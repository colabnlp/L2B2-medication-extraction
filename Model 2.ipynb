{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "\n",
    "import Functions as fn\n",
    "from DS import DS\n",
    "from Set import pool\n",
    "from Iterator import Iterator\n",
    "from FFModel import FF_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dataset = pool()\n",
    "Dataset.load_texts('raw_texts')\n",
    "Dataset.load_labels('raw_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print('Number of Texts: ', Dataset.size)\n",
    "#print('Number of 2007 Smoking Challenge texts: ', Dataset.number_of(challenge='2007 Smoking Challenge'))\n",
    "#print('Number of 2008 ObesityChallenge texts: ', Dataset.number_of(challenge='2008 Obesity Challenge'))\n",
    "#print('Number of 2009 Medication Challenge texts: ', Dataset.number_of(challenge='2009 Medication Challenge'))\n",
    "#print('Number of 2010 Relations Challenge texts: ', Dataset.number_of(challenge='2010 Relations Challenge'))\n",
    "#print('Number of 2011 Coreference Challenge texts: ', Dataset.number_of(challenge='2011 Coreference Challenge'))\n",
    "#print('Number of 2012 Temporal Relations Challenge texts: ', Dataset.number_of(challenge='2012 Temporal Relations Challenge'))\n",
    "#print('Number of Train Texts: ', Dataset.number_of(stage='train'))\n",
    "#print('Number of Test Texts: ', Dataset.number_of(stage='test'))\n",
    "#print('Number of Labeled Texts: ', Dataset.number_of(labelled='yes'))\n",
    "#print('Number of Initially Labeled Texts: ', Dataset.number_of(labelled='yes', label_type='train'))\n",
    "#print('Number of Competitor Labeled Texts Texts: ', Dataset.number_of(labelled='yes', label_type='test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "target_dict = fn.load_labels('labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = fn.load_sentences('sentences')\n",
    "\n",
    "#model = Word2Vec(sentences, min_count=1, size=100)\n",
    "#model.save('W2V')\n",
    "\n",
    "model = Word2Vec.load('W2V')\n",
    "vocab = model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.most_similar(\"prozac\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFNN Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelled_cases = Dataset.get_DS(labelled='yes')\n",
    "labelled_cases.process_for_testing()\n",
    "sets = fn.get_ff_traintest(labelled_cases, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Ratio: med: {:.2f}% non-med: {:.2f}%'.format(*(np.array(sets['train_labels']).sum(0)/ len(sets['train_labels']))))\n",
    "fn.saturate_training_set_labels(sets, model, target_dict['medications'], 0.1)\n",
    "print('Ratio: med: {:.2f}% non-med: {:.2f}%'.format(*(np.array(sets['train_labels']).sum(0)/ len(sets['train_labels']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN = FF_Model(layers=[50])\n",
    "NN.build_graph()\n",
    "_,_,_,_ = NN.train(sets, epochs=10, batch=50, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = NN.predict(sets['test_set'])\n",
    "tru = np.argmax(sets['test_labels'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TP = len([a for a in range(len(tru)) if (res[a] == 0) and (tru[a] == 0)])\n",
    "TN = len([a for a in range(len(tru)) if (res[a] == 1) and (tru[a] == 1)])\n",
    "FP = len([a for a in range(len(tru)) if (res[a] == 0) and (tru[a] == 1)])\n",
    "FN = len([a for a in range(len(tru)) if (res[a] == 1) and (tru[a] == 0)])\n",
    "TFPN = [TP, TN, FP, FN]\n",
    "print('TP\\tTN\\tFP\\tFN\\n{}\\t{}\\t{}\\t{}'.format(*TFPN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[(sets['test_words'][a], res[a], tru[a]) for a in range(len(sets['test_words'])) if res[a] == 1 and tru[a] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba = []\n",
    "for i in range(len(res)):\n",
    "    if not (sets['test_words'][i] == ')' or sets['test_words'][i] == '('):\n",
    "        proba.append([sets['test_words'][i], res[i], tru[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sk.metrics.f1_score(np.array(proba)[:,2].astype(int), np.array(proba)[:,1].astype(int), pos_label=0, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len([(proba[a][0], proba[a][1], proba[a][2]) for a in range(len(proba)) if proba[a][1] == 0 and proba[a][2] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[(proba[a][0], proba[a][1], proba[a][2]) for a in range(len(proba)) if proba[a][1] == 1 and proba[a][2] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_num = 1\n",
    "NN_num = 1\n",
    "emb_sizes = [30, 50, 100]\n",
    "target_saturations = [0.05, 0.1, 0.3]\n",
    "layers = [[30], [50], [100]]\n",
    "dropouts = [0.3, 0.5, 0.8, 1.0]\n",
    "learn_rates = [0.001, 0.01, 0.1]\n",
    "epoch_nums = [10, 50, 100]\n",
    "batch_sizes = [10, 50, 100]\n",
    "\n",
    "\n",
    "model_num = emb_num * NN_num * len(emb_sizes) * len(layers) * len(dropouts) * \\\n",
    "            len(learn_rates) * len(epoch_nums) * len(batch_sizes) * len(target_saturations)\n",
    "target = target_dict['medications']\n",
    "report_percentage = 10\n",
    "\n",
    "print(model_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelled_cases = Dataset.get_DS(labelled='yes')\n",
    "labelled_cases.process_for_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterations = [emb_sizes, target_saturations, layers, dropouts, learn_rates, epoch_nums, batch_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "parameters = []\n",
    "results = []\n",
    "timestamp = re.sub(r':', '-', str(datetime.datetime.now()).split('.')[0])\n",
    "\n",
    "f = open('tests/Model2/' + timestamp, 'w+')\n",
    "print('EmbSz:\\tSat:\\tLay:\\tDrop:\\tLeRa:\\tEpochs:\\tBatSz:\\tF1:')\n",
    "f.write('EmbSz:\\tSat:\\tLay:\\tDrop:\\tLeRa:\\tEpochs:\\tBatSz:\\tF1:\\n')\n",
    "for par in itertools.product(*iterations):\n",
    "    best = 0\n",
    "    parameters.append(par)\n",
    "    for i in range(emb_num):\n",
    "        model = Word2Vec(sentences, min_count=1, size=par[0])\n",
    "        sets = fn.get_ff_traintest(labelled_cases, model)\n",
    "        fn.saturate_training_set_labels(sets, model, target, par[1])\n",
    "        for j in range(NN_num):\n",
    "            n += 1\n",
    "            print('Model Number: {}/{}'.format(n, model_num), end='\\r')\n",
    "            NN = FF_Model(input_size=par[0], layers=par[2], dropout=par[3], learn_rate=par[4])\n",
    "            NN.build_graph()\n",
    "            _, _, _, score = NN.train(sets, epochs=par[5], batch=par[6], report_percentage=report_percentage)\n",
    "            best = max(best, score)\n",
    "    results.append(best)\n",
    "    print('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{:.4f}'.format(*parameters[-1], results[-1]))\n",
    "    f.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{:.4f}\\n'.format(*parameters[-1], results[-1]))\n",
    "    \n",
    "print('Max Performance: {:.4f}'.format(max(results)))  \n",
    "f.write('Max Performance: {:.4f}\\n'.format(max(results)))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
