{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "\n",
    "import Functions as fn\n",
    "from DS import DS\n",
    "from Set import pool\n",
    "from Iterator import Iterator\n",
    "from FFModel import FF_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Text Load Complete\n",
      "Raw Labels Load Complete\n"
     ]
    }
   ],
   "source": [
    "Dataset = pool()\n",
    "Dataset.load_texts('raw_texts')\n",
    "Dataset.load_labels('raw_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print('Number of Texts: ', Dataset.size)\n",
    "#print('Number of 2007 Smoking Challenge texts: ', Dataset.number_of(challenge='2007 Smoking Challenge'))\n",
    "#print('Number of 2008 ObesityChallenge texts: ', Dataset.number_of(challenge='2008 Obesity Challenge'))\n",
    "#print('Number of 2009 Medication Challenge texts: ', Dataset.number_of(challenge='2009 Medication Challenge'))\n",
    "#print('Number of 2010 Relations Challenge texts: ', Dataset.number_of(challenge='2010 Relations Challenge'))\n",
    "#print('Number of 2011 Coreference Challenge texts: ', Dataset.number_of(challenge='2011 Coreference Challenge'))\n",
    "#print('Number of 2012 Temporal Relations Challenge texts: ', Dataset.number_of(challenge='2012 Temporal Relations Challenge'))\n",
    "#print('Number of Train Texts: ', Dataset.number_of(stage='train'))\n",
    "#print('Number of Test Texts: ', Dataset.number_of(stage='test'))\n",
    "#print('Number of Labeled Texts: ', Dataset.number_of(labelled='yes'))\n",
    "#print('Number of Initially Labeled Texts: ', Dataset.number_of(labelled='yes', label_type='train'))\n",
    "#print('Number of Competitor Labeled Texts Texts: ', Dataset.number_of(labelled='yes', label_type='test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Load Complete\n"
     ]
    }
   ],
   "source": [
    "target_dict = fn.load_labels('labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luka\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Load Complete\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = fn.load_sentences('sentences')\n",
    "\n",
    "#model = Word2Vec(sentences, min_count=1, size=100)\n",
    "#model.save('W2V')\n",
    "\n",
    "model = Word2Vec.load('W2V')\n",
    "vocab = model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.most_similar(\"prozac\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fn.visualise(model, sentences, [target_dict['medications']], 1000, 'Medications in top 1000 words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print_set = []\n",
    "#for case in Dataset.get_DS(labelled='yes').data:\n",
    "#    for term in re.finditer(r'm=\"[^|]+\\|', case.raw_labels):\n",
    "#        print_set.append(term.group()[:-1])\n",
    "#print(*print_set, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFNN Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelled_cases = Dataset.get_DS(labelled='yes')\n",
    "labelled_cases.process_for_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sets = fn.get_ff_traintest(labelled_cases, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio: med: 0.03% non-med: 0.97%\n"
     ]
    }
   ],
   "source": [
    "print('Ratio: med: {:.2f}% non-med: {:.2f}%'.format(*(np.array(sets['train_labels']).sum(0)/ len(sets['train_labels']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label proportion: 0.100290\r"
     ]
    }
   ],
   "source": [
    "fn.saturate_training_set_labels(sets, model, target_dict['medications'], 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FInal Values: TrAcc: 0.963, ValAcc: 0.967, ValF1: 0.596\n",
      "Test F1-Score: 0.576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN = FF_Model(layers=[50])\n",
    "NN.build_graph()\n",
    "_,_,_,_ = NN.train(sets, epochs=10, batch=50, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = NN.predict(sets['test_set'])\n",
    "tru = np.argmax(sets['test_labels'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP\tTN\tFP\tFN\n",
      "531\t27201\t574\t208\n"
     ]
    }
   ],
   "source": [
    "TP = len([a for a in range(len(tru)) if (res[a] == 0) and (tru[a] == 0)])\n",
    "TN = len([a for a in range(len(tru)) if (res[a] == 1) and (tru[a] == 1)])\n",
    "FP = len([a for a in range(len(tru)) if (res[a] == 0) and (tru[a] == 1)])\n",
    "FN = len([a for a in range(len(tru)) if (res[a] == 1) and (tru[a] == 0)])\n",
    "TFPN = [TP, TN, FP, FN]\n",
    "print('TP\\tTN\\tFP\\tFN\\n{}\\t{}\\t{}\\t{}'.format(*TFPN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[(sets['test_words'][a], res[a], tru[a]) for a in range(len(sets['test_words'])) if res[a] == 1 and tru[a] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba = []\n",
    "for i in range(len(res)):\n",
    "    if not (sets['test_words'][i] == ')' or sets['test_words'][i] == '('):\n",
    "        proba.append([sets['test_words'][i], res[i], tru[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk.metrics.f1_score(np.array(proba)[:,2].astype(int), np.array(proba)[:,1].astype(int), pos_label=0, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([(proba[a][0], proba[a][1], proba[a][2]) for a in range(len(proba)) if proba[a][1] == 0 and proba[a][2] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[(proba[a][0], proba[a][1], proba[a][2]) for a in range(len(proba)) if proba[a][1] == 1 and proba[a][2] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_sizes = [100]\n",
    "emb_models = 1\n",
    "target_saturations = [0.05, 0.1, 0.2, 0.5, 0.7]\n",
    "layer_sizes = [50]\n",
    "dropouts = [1.0]\n",
    "learn_rates = [0.01]\n",
    "epochs = [100]\n",
    "NN_num = 5\n",
    "\n",
    "case_num = len(emb_sizes)*emb_models*len(layer_sizes)*len(target_saturations)*len(epochs)*len(dropouts)*len(learn_rates)*NN_num\n",
    "print(case_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_performance = 0\n",
    "n = 1\n",
    "\n",
    "for emb_size in emb_sizes:\n",
    "    print('Model Number: %d/%d' %(n, case_num))\n",
    "    for i in range(emb_models):\n",
    "        model = Word2Vec(sentences, min_count=1, size=emb_size)\n",
    "        for saturation in target_saturations:\n",
    "            sets = fn.get_traintest2 (labelled_cases, model)\n",
    "            fn.saturate_training_set(sets, model, target_dict['medications'], saturation)\n",
    "            for layer_size in layer_sizes:\n",
    "                for drop in dropouts:\n",
    "                    for rate in learn_rates:\n",
    "                        for epoch in epochs:\n",
    "                            for j in range(NN_num):\n",
    "                                print('Model Number: %d/%d' %(n, case_num))\n",
    "                                print('ES: %d EM: %d sat: %f, LS: %d, drop: %f, LR: %f, epochs: %d, NN: %d' \\\n",
    "                                       % (emb_size, i, saturation, layer_size, drop, rate, epoch, j))\n",
    "                                NN = FF_Model(input_size=emb_size, layers=[layer_size], dropout=drop, learn_rate=rate)\n",
    "                                NN.build_graph()\n",
    "                                NN.train(sets, epochs=epoch)\n",
    "                                res = NN.predict(sets['test_set'])\n",
    "                                tru = np.argmax(sets['test_labels'], 1)\n",
    "                                perf = sk.metrics.f1_score(tru, res, pos_label=0)\n",
    "                                if perf > max_performance:\n",
    "                                    max_performance = perf\n",
    "                                    NN.save_model('gold')\n",
    "                                    model.save('gold/GOLDEMB')\n",
    "                                NN.close()\n",
    "                                n += 1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
