{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "\n",
    "import Functions as fn\n",
    "from DS import DS\n",
    "from Set import pool\n",
    "from Iterator import Iterator\n",
    "from FFModel import FF_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Text Load Complete\n",
      "Raw Labels Load Complete\n"
     ]
    }
   ],
   "source": [
    "Dataset = pool()\n",
    "Dataset.load_texts('raw_texts')\n",
    "Dataset.load_labels('raw_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print('Number of Texts: ', Dataset.size)\n",
    "#print('Number of 2007 Smoking Challenge texts: ', Dataset.number_of(challenge='2007 Smoking Challenge'))\n",
    "#print('Number of 2008 ObesityChallenge texts: ', Dataset.number_of(challenge='2008 Obesity Challenge'))\n",
    "#print('Number of 2009 Medication Challenge texts: ', Dataset.number_of(challenge='2009 Medication Challenge'))\n",
    "#print('Number of 2010 Relations Challenge texts: ', Dataset.number_of(challenge='2010 Relations Challenge'))\n",
    "#print('Number of 2011 Coreference Challenge texts: ', Dataset.number_of(challenge='2011 Coreference Challenge'))\n",
    "#print('Number of 2012 Temporal Relations Challenge texts: ', Dataset.number_of(challenge='2012 Temporal Relations Challenge'))\n",
    "#print('Number of Train Texts: ', Dataset.number_of(stage='train'))\n",
    "#print('Number of Test Texts: ', Dataset.number_of(stage='test'))\n",
    "#print('Number of Labeled Texts: ', Dataset.number_of(labelled='yes'))\n",
    "#print('Number of Initially Labeled Texts: ', Dataset.number_of(labelled='yes', label_type='train'))\n",
    "#print('Number of Competitor Labeled Texts Texts: ', Dataset.number_of(labelled='yes', label_type='test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Load Complete\n"
     ]
    }
   ],
   "source": [
    "target_dict = fn.load_labels('labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luka\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Load Complete\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = fn.load_sentences('sentences')\n",
    "\n",
    "#model = Word2Vec(sentences, min_count=1, size=100)\n",
    "#model.save('W2V')\n",
    "\n",
    "model = Word2Vec.load('W2V')\n",
    "vocab = model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.most_similar(\"prozac\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fn.visualise(model, sentences, [target_dict['medications']], 1000, 'Medications in top 1000 words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print_set = []\n",
    "#for case in Dataset.get_DS(labelled='yes').data:\n",
    "#    for term in re.finditer(r'm=\"[^|]+\\|', case.raw_labels):\n",
    "#        print_set.append(term.group()[:-1])\n",
    "#print(*print_set, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFNN Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelled_cases = Dataset.get_DS(labelled='yes')\n",
    "labelled_cases.process_for_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sets = fn.get_traintest2(labelled_cases, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio: med: 0.03% non-med: 0.97%\n"
     ]
    }
   ],
   "source": [
    "print('Ratio: med: {:.2f}% non-med: {:.2f}%'.format(*(np.array(sets['train_labels']).sum(0)/ len(sets['train_labels']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label proportion: 0.100290\r"
     ]
    }
   ],
   "source": [
    "fn.saturate_training_set(sets, model, target_dict['medications'], 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FInal Values: TrAcc: 0.962, ValAcc: 0.968, ValF1: 0.621\n",
      "Test F1-Score: 0.598\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.10029014,\n",
       "  0.94254273,\n",
       "  0.94985884,\n",
       "  0.95338589,\n",
       "  0.95378864,\n",
       "  0.95514941,\n",
       "  0.95507902,\n",
       "  0.95567727,\n",
       "  0.95547396,\n",
       "  0.95627946,\n",
       "  0.95660794,\n",
       "  0.95768327,\n",
       "  0.95779663,\n",
       "  0.95831281,\n",
       "  0.95792568,\n",
       "  0.95863342,\n",
       "  0.9578436,\n",
       "  0.9581486,\n",
       "  0.95769107,\n",
       "  0.95921218,\n",
       "  0.95877421,\n",
       "  0.95925128,\n",
       "  0.95889151,\n",
       "  0.95916134,\n",
       "  0.95799607,\n",
       "  0.96022099,\n",
       "  0.96024835,\n",
       "  0.95926297,\n",
       "  0.96015847,\n",
       "  0.95993167,\n",
       "  0.95749164,\n",
       "  0.95753855,\n",
       "  0.95996684,\n",
       "  0.9601506,\n",
       "  0.96027964,\n",
       "  0.9594937,\n",
       "  0.95974398,\n",
       "  0.96042043,\n",
       "  0.96016234,\n",
       "  0.96052992,\n",
       "  0.96081144,\n",
       "  0.9598065,\n",
       "  0.95977521,\n",
       "  0.95997077,\n",
       "  0.96047908,\n",
       "  0.96063161,\n",
       "  0.96054167,\n",
       "  0.96106952,\n",
       "  0.9587273,\n",
       "  0.96087009,\n",
       "  0.96138626,\n",
       "  0.9598065,\n",
       "  0.95995122,\n",
       "  0.96044391,\n",
       "  0.96151531,\n",
       "  0.96128458,\n",
       "  0.96149963,\n",
       "  0.96128851,\n",
       "  0.96152312,\n",
       "  0.96205103,\n",
       "  0.96193367,\n",
       "  0.96023273,\n",
       "  0.96203536,\n",
       "  0.96115947,\n",
       "  0.96182424,\n",
       "  0.96153092,\n",
       "  0.96205491,\n",
       "  0.96213311,\n",
       "  0.96088576,\n",
       "  0.96199232,\n",
       "  0.96150357,\n",
       "  0.96223867,\n",
       "  0.96201187,\n",
       "  0.96148401,\n",
       "  0.96230125,\n",
       "  0.96121418,\n",
       "  0.96179295,\n",
       "  0.96152312,\n",
       "  0.9622035,\n",
       "  0.96101087,\n",
       "  0.96239901,\n",
       "  0.96196496,\n",
       "  0.96225041,\n",
       "  0.96236384,\n",
       "  0.96257889,\n",
       "  0.96238339,\n",
       "  0.96233255,\n",
       "  0.96101087,\n",
       "  0.96210968,\n",
       "  0.96122593,\n",
       "  0.96203929,\n",
       "  0.96234035,\n",
       "  0.96269619,\n",
       "  0.96249288,\n",
       "  0.96269619,\n",
       "  0.96287608,\n",
       "  0.96207446,\n",
       "  0.96177727,\n",
       "  0.96287215,\n",
       "  0.96180075,\n",
       "  0.9622348],\n",
       " [0.035430733,\n",
       "  0.95722342,\n",
       "  0.96130443,\n",
       "  0.95974624,\n",
       "  0.96430957,\n",
       "  0.95989466,\n",
       "  0.96219486,\n",
       "  0.96564519,\n",
       "  0.96583068,\n",
       "  0.96453214,\n",
       "  0.96560806,\n",
       "  0.96475476,\n",
       "  0.96479189,\n",
       "  0.96490318,\n",
       "  0.9657194,\n",
       "  0.96430957,\n",
       "  0.96660978,\n",
       "  0.96327078,\n",
       "  0.96260297,\n",
       "  0.96479189,\n",
       "  0.96271425,\n",
       "  0.96516287,\n",
       "  0.96468055,\n",
       "  0.96616459,\n",
       "  0.96327078,\n",
       "  0.96519995,\n",
       "  0.96549678,\n",
       "  0.96701789,\n",
       "  0.96464348,\n",
       "  0.96735179,\n",
       "  0.96764857,\n",
       "  0.96041405,\n",
       "  0.96527416,\n",
       "  0.96408695,\n",
       "  0.9651258,\n",
       "  0.96386439,\n",
       "  0.96364176,\n",
       "  0.96560806,\n",
       "  0.96750021,\n",
       "  0.967426,\n",
       "  0.96590489,\n",
       "  0.96334493,\n",
       "  0.96490318,\n",
       "  0.96660978,\n",
       "  0.96534836,\n",
       "  0.96549678,\n",
       "  0.96508867,\n",
       "  0.96579355,\n",
       "  0.96757436,\n",
       "  0.96575648,\n",
       "  0.96605325,\n",
       "  0.96727759,\n",
       "  0.96698076,\n",
       "  0.96468055,\n",
       "  0.96686947,\n",
       "  0.96705496,\n",
       "  0.96583068,\n",
       "  0.96594197,\n",
       "  0.96646136,\n",
       "  0.9665727,\n",
       "  0.96545964,\n",
       "  0.96790826,\n",
       "  0.96686947,\n",
       "  0.96501446,\n",
       "  0.96601617,\n",
       "  0.96731466,\n",
       "  0.96627587,\n",
       "  0.96646136,\n",
       "  0.9653855,\n",
       "  0.9665727,\n",
       "  0.96616459,\n",
       "  0.96720338,\n",
       "  0.9662388,\n",
       "  0.96724051,\n",
       "  0.96649849,\n",
       "  0.96501446,\n",
       "  0.9653855,\n",
       "  0.96505159,\n",
       "  0.966313,\n",
       "  0.96557099,\n",
       "  0.96731466,\n",
       "  0.96616459,\n",
       "  0.96649849,\n",
       "  0.96694368,\n",
       "  0.96653557,\n",
       "  0.9670921,\n",
       "  0.96627587,\n",
       "  0.96456927,\n",
       "  0.96583068,\n",
       "  0.9659791,\n",
       "  0.96761149,\n",
       "  0.96646136,\n",
       "  0.96553385,\n",
       "  0.96609038,\n",
       "  0.96653557,\n",
       "  0.96694368,\n",
       "  0.96757436,\n",
       "  0.96720338,\n",
       "  0.96668398,\n",
       "  0.96805668,\n",
       "  0.96809381],\n",
       " [0.068436705005553766,\n",
       "  0.48133153396311285,\n",
       "  0.52177900045850523,\n",
       "  0.5361265498076101,\n",
       "  0.56744604316546765,\n",
       "  0.53823152498932081,\n",
       "  0.53192466697289853,\n",
       "  0.58586762075134169,\n",
       "  0.59799214316892191,\n",
       "  0.54648956356736245,\n",
       "  0.59783080260303689,\n",
       "  0.58587619877942465,\n",
       "  0.59322760394342045,\n",
       "  0.58325991189427306,\n",
       "  0.57497700091996318,\n",
       "  0.54750705550329271,\n",
       "  0.58410351201478738,\n",
       "  0.52676864244741883,\n",
       "  0.51585014409221897,\n",
       "  0.56085145765849143,\n",
       "  0.52301850972947317,\n",
       "  0.56588072122052702,\n",
       "  0.550519357884797,\n",
       "  0.57541899441340771,\n",
       "  0.5544554455445545,\n",
       "  0.57129798903107853,\n",
       "  0.59388646288209612,\n",
       "  0.58937644341801387,\n",
       "  0.58583224684919599,\n",
       "  0.59145775301764159,\n",
       "  0.57170923379174865,\n",
       "  0.51477944520236463,\n",
       "  0.59162303664921467,\n",
       "  0.58419243986254288,\n",
       "  0.54545454545454541,\n",
       "  0.59109991603694378,\n",
       "  0.54205607476635509,\n",
       "  0.55751789976133637,\n",
       "  0.61578947368421055,\n",
       "  0.5807067812798471,\n",
       "  0.56834194457491782,\n",
       "  0.56590509666080846,\n",
       "  0.54077669902912617,\n",
       "  0.57507082152974509,\n",
       "  0.57584014532243422,\n",
       "  0.57339449541284393,\n",
       "  0.54650602409638549,\n",
       "  0.57822506861848122,\n",
       "  0.58656575212866602,\n",
       "  0.55432158377595353,\n",
       "  0.57262961233068665,\n",
       "  0.57677543186180424,\n",
       "  0.55984174085064287,\n",
       "  0.57309417040358746,\n",
       "  0.61291720849588205,\n",
       "  0.59377859103385178,\n",
       "  0.59121171770972036,\n",
       "  0.57222739981360671,\n",
       "  0.57478833490122294,\n",
       "  0.58802011888431638,\n",
       "  0.5663716814159292,\n",
       "  0.59636024265048992,\n",
       "  0.60151717983043285,\n",
       "  0.58144695960940973,\n",
       "  0.5907059874888293,\n",
       "  0.58107465525439839,\n",
       "  0.56776034236804562,\n",
       "  0.59279279279279273,\n",
       "  0.56544014904517947,\n",
       "  0.57479943369513919,\n",
       "  0.59394479073909168,\n",
       "  0.60711111111111116,\n",
       "  0.58673932788374206,\n",
       "  0.59588100686498857,\n",
       "  0.59084730403262342,\n",
       "  0.54988066825775661,\n",
       "  0.54421104054714209,\n",
       "  0.57064721969006393,\n",
       "  0.58386801099908336,\n",
       "  0.56917363045496749,\n",
       "  0.60510981622590765,\n",
       "  0.59029649595687328,\n",
       "  0.59195661997288751,\n",
       "  0.60205448861098709,\n",
       "  0.58775137111517373,\n",
       "  0.61684665226781865,\n",
       "  0.58625398270368689,\n",
       "  0.56806874717322475,\n",
       "  0.56536101934874938,\n",
       "  0.5366346639717029,\n",
       "  0.59071729957805907,\n",
       "  0.58683729433272391,\n",
       "  0.56810785681078568,\n",
       "  0.56967984934086635,\n",
       "  0.58925318761384338,\n",
       "  0.59955056179775279,\n",
       "  0.60416666666666663,\n",
       "  0.56367226061204345,\n",
       "  0.60124333925399642,\n",
       "  0.62120545534535854,\n",
       "  0.62147887323943662],\n",
       " 0.59754142169962587)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = FF_Model(layers=[50])\n",
    "NN.build_graph()\n",
    "_,_,_,_ = NN.train(sets, epochs=10, batch=50, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = NN.predict(sets['test_set'])\n",
    "tru = np.argmax(sets['test_labels'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP\tTN\tFP\tFN\n",
      "559\t27202\t573\t180\n"
     ]
    }
   ],
   "source": [
    "tp = len([a for a in range(len(tru)) if (res[a] == 0) and (tru[a] == 0)])\n",
    "tn = len([a for a in range(len(tru)) if (res[a] == 1) and (tru[a] == 1)])\n",
    "fp = len([a for a in range(len(tru)) if (res[a] == 0) and (tru[a] == 1)])\n",
    "fn = len([a for a in range(len(tru)) if (res[a] == 1) and (tru[a] == 0)])\n",
    "tfpn = [tp, tn, fp, fn]\n",
    "print('TP\\tTN\\tFP\\tFN\\n{}\\t{}\\t{}\\t{}'.format(*tfpn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[(sets['test_words'][a], res[a], tru[a]) for a in range(len(sets['test_words'])) if res[a] == 1 and tru[a] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba = []\n",
    "for i in range(len(res)):\n",
    "    if not (sets['test_words'][i] == ')' or sets['test_words'][i] == '('):\n",
    "        proba.append([sets['test_words'][i], res[i], tru[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63667425968109337"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk.metrics.f1_score(np.array(proba)[:,2].astype(int), np.array(proba)[:,1].astype(int), pos_label=0, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([(proba[a][0], proba[a][1], proba[a][2]) for a in range(len(proba)) if proba[a][1] == 0 and proba[a][2] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lovenox', 1, 0),\n",
       " ('<num>/<num>', 1, 0),\n",
       " ('penicillin', 1, 0),\n",
       " ('penicillin', 1, 0),\n",
       " ('normal', 1, 0),\n",
       " ('lovenox', 1, 0),\n",
       " ('copd', 1, 0),\n",
       " ('medications', 1, 0),\n",
       " ('oxygen', 1, 0),\n",
       " ('oxygen', 1, 0),\n",
       " ('mg', 1, 0),\n",
       " ('amoxicil...', 1, 0),\n",
       " ('previous', 1, 0),\n",
       " ('home', 1, 0),\n",
       " ('medications', 1, 0),\n",
       " ('pain', 1, 0),\n",
       " ('medications', 1, 0),\n",
       " ('red', 1, 0),\n",
       " ('blood', 1, 0),\n",
       " ('cells', 1, 0),\n",
       " ('red', 1, 0),\n",
       " ('blood', 1, 0),\n",
       " ('cells', 1, 0),\n",
       " ('red', 1, 0),\n",
       " ('blood', 1, 0),\n",
       " ('cells', 1, 0),\n",
       " ('nebulizer', 1, 0),\n",
       " ('nebulizer', 1, 0),\n",
       " ('lovenox', 1, 0),\n",
       " ('lovenox', 1, 0),\n",
       " ('tablets', 1, 0),\n",
       " ('general', 1, 0),\n",
       " ('anesthesia', 1, 0),\n",
       " ('<num>/<num>', 1, 0),\n",
       " ('penicillin', 1, 0),\n",
       " ('tablets', 1, 0),\n",
       " ('therapeutic', 1, 0),\n",
       " ('therapeutic', 1, 0),\n",
       " ('controlled', 1, 0),\n",
       " ('<num>/<num>', 1, 0),\n",
       " ('+', 1, 0),\n",
       " ('d', 1, 0),\n",
       " ('<num>', 1, 0),\n",
       " (',', 1, 0),\n",
       " ('<num>', 1, 0),\n",
       " ('mg', 1, 0),\n",
       " ('<num>', 1, 0),\n",
       " ('<num>/<num>', 1, 0),\n",
       " ('<num>/<num>', 1, 0),\n",
       " ('slow', 1, 0),\n",
       " ('<num>/<num>', 1, 0),\n",
       " ('lovenox', 1, 0),\n",
       " ('strength', 1, 0),\n",
       " ('propionate/salmeterol', 1, 0),\n",
       " ('<num>/<num>', 1, 0),\n",
       " ('nebulizer', 1, 0),\n",
       " ('nebulizer', 1, 0),\n",
       " ('until', 1, 0),\n",
       " ('asa;', 1, 0),\n",
       " ('slow', 1, 0),\n",
       " ('therapeutic', 1, 0),\n",
       " ('therapeutic', 1, 0),\n",
       " ('medications', 1, 0),\n",
       " ('slow', 1, 0),\n",
       " ('slow', 1, 0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(proba[a][0], proba[a][1], proba[a][2]) for a in range(len(proba)) if proba[a][1] == 1 and proba[a][2] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_sizes = [100]\n",
    "emb_models = 1\n",
    "target_saturations = [0.05, 0.1, 0.2, 0.5, 0.7]\n",
    "layer_sizes = [50]\n",
    "dropouts = [1.0]\n",
    "learn_rates = [0.01]\n",
    "epochs = [100]\n",
    "NN_num = 5\n",
    "\n",
    "case_num = len(emb_sizes)*emb_models*len(layer_sizes)*len(target_saturations)*len(epochs)*len(dropouts)*len(learn_rates)*NN_num\n",
    "print(case_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_performance = 0\n",
    "n = 1\n",
    "\n",
    "for emb_size in emb_sizes:\n",
    "    print('Model Number: %d/%d' %(n, case_num))\n",
    "    for i in range(emb_models):\n",
    "        model = Word2Vec(sentences, min_count=1, size=emb_size)\n",
    "        for saturation in target_saturations:\n",
    "            sets = fn.get_traintest2 (labelled_cases, model)\n",
    "            fn.saturate_training_set(sets, model, target_dict['medications'], saturation)\n",
    "            for layer_size in layer_sizes:\n",
    "                for drop in dropouts:\n",
    "                    for rate in learn_rates:\n",
    "                        for epoch in epochs:\n",
    "                            for j in range(NN_num):\n",
    "                                print('Model Number: %d/%d' %(n, case_num))\n",
    "                                print('ES: %d EM: %d sat: %f, LS: %d, drop: %f, LR: %f, epochs: %d, NN: %d' \\\n",
    "                                       % (emb_size, i, saturation, layer_size, drop, rate, epoch, j))\n",
    "                                NN = FF_Model(input_size=emb_size, layers=[layer_size], dropout=drop, learn_rate=rate)\n",
    "                                NN.build_graph()\n",
    "                                NN.train(sets, epochs=epoch)\n",
    "                                res = NN.predict(sets['test_set'])\n",
    "                                tru = np.argmax(sets['test_labels'], 1)\n",
    "                                perf = sk.metrics.f1_score(tru, res, pos_label=0)\n",
    "                                if perf > max_performance:\n",
    "                                    max_performance = perf\n",
    "                                    NN.save_model('gold')\n",
    "                                    model.save('gold/GOLDEMB')\n",
    "                                NN.close()\n",
    "                                n += 1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
