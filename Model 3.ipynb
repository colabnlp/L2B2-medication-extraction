{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "\n",
    "import Functions as fn\n",
    "from DS import DS\n",
    "from Set import pool\n",
    "from Iterator import Iterator\n",
    "from FFModel import FF_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts loaded\n",
      "Labels loaded\n"
     ]
    }
   ],
   "source": [
    "#Dataset = fn.first_time_load()\n",
    "#Dataset.write_texts()\n",
    "#Dataset.write_labels()\n",
    "\n",
    "Dataset = pool()\n",
    "Dataset.load_texts()\n",
    "Dataset.load_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print('Number of Texts: ', Dataset.size)\n",
    "#print('Number of 2007 Smoking Challenge texts: ', Dataset.number_of(challenge='2007 Smoking Challenge'))\n",
    "#print('Number of 2008 ObesityChallenge texts: ', Dataset.number_of(challenge='2008 Obesity Challenge'))\n",
    "#print('Number of 2009 Medication Challenge texts: ', Dataset.number_of(challenge='2009 Medication Challenge'))\n",
    "#print('Number of 2010 Relations Challenge texts: ', Dataset.number_of(challenge='2010 Relations Challenge'))\n",
    "#print('Number of 2011 Coreference Challenge texts: ', Dataset.number_of(challenge='2011 Coreference Challenge'))\n",
    "#print('Number of 2012 Temporal Relations Challenge texts: ', Dataset.number_of(challenge='2012 Temporal Relations Challenge'))\n",
    "#print('Number of Train Texts: ', Dataset.number_of(stage='train'))\n",
    "#print('Number of Test Texts: ', Dataset.number_of(stage='test'))\n",
    "#print('Number of Labeled Texts: ', Dataset.number_of(labelled='yes'))\n",
    "#print('Number of Initially Labeled Texts: ', Dataset.number_of(labelled='yes', label_type='train'))\n",
    "#print('Number of Competitor Labeled Texts Texts: ', Dataset.number_of(labelled='yes', label_type='test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dataset.process_for_embedding()\n",
    "#sentences = Dataset.get_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luka\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "#model = Word2Vec(sentences, min_count=1, size=100)\n",
    "model = Word2Vec.load('W2V')\n",
    "\n",
    "#fn.write_emb('testemb', model)\n",
    "#model = fn.load_emb('testemb')\n",
    "#model.save('W2V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.most_similar(\"prozac\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of: m=1327, do=190, mo=104, f=227, du=178, r=715\n"
     ]
    }
   ],
   "source": [
    "targets = ['medications', 'dosages', 'modes', 'frequencies', 'durations', 'reasons']\n",
    "target_dict = {label: words for (label, words) in zip(targets, list(fn.label_words(Dataset, model)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fn.visualise(model, sentences, [target_dict['medications']], 1000, 'Medications in top 1000 words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print_set = []\n",
    "#for case in Dataset.get_DS(labelled='yes').data:\n",
    "#    for term in re.finditer(r'm=\"[^|]+\\|', case.raw_labels):\n",
    "#        print_set.append(term.group()[:-1])\n",
    "#print(*print_set, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for target in targets:\n",
    "#    for reps in [True, False]:\n",
    "#        target_size = len(target_dict[target])\n",
    "#        sets = fn.get_traintest(model, target_dict[target], target_size * 5, target_size, 10, 50, reps, reps)\n",
    "#        sets = {'train_set': sets[0], 'train_labels': sets[1], 'validation_set': sets[2], 'validation_labels': sets[3], 'test_set': sets[2], 'test_labels': sets[3]}\n",
    "#        print(\"Target: %s \\tRepetitions: %s\" % (target, reps))\n",
    "#        NN = FF_Model()\n",
    "#        NN.build_graph()\n",
    "#        NN.train(sets, report_percentage=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFNN Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelled_cases = Dataset.get_DS(labelled='yes')\n",
    "labelled_cases.process_for_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#emb_sizes = [100]\n",
    "#emb_models = 5\n",
    "#target_saturations = [0.1]\n",
    "#layer_sizes = [100]\n",
    "#dropouts = [1.0]\n",
    "#learn_rates = [0.01]\n",
    "#epochs = [100]\n",
    "#NN_num = 5\n",
    "\n",
    "#case_num = len(emb_sizes)*emb_models*len(layer_sizes)*len(target_saturations)*len(epochs)*len(dropouts)*len(learn_rates)*NN_num\n",
    "#print(case_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_performance = 0\n",
    "n = 1\n",
    "\n",
    "for emb_size in emb_sizes:\n",
    "    print('Model Number: %d/%d' %(n, case_num))\n",
    "    for i in range(emb_models):\n",
    "        model = Word2Vec(sentences, min_count=1, size=emb_size)\n",
    "        for saturation in target_saturations:\n",
    "            sets = fn.get_traintest2 (labelled_cases, model)\n",
    "            fn.saturate_training_set(sets, model, target_dict['medications'], saturation)\n",
    "            for layer_size in layer_sizes:\n",
    "                for drop in dropouts:\n",
    "                    for rate in learn_rates:\n",
    "                        for epoch in epochs:\n",
    "                            for j in range(NN_num):\n",
    "                                print('Model Number: %d/%d' %(n, case_num))\n",
    "                                print('ES: %d EM: %d sat: %f, LS: %d, drop: %f, LR: %f, epochs: %d, NN: %d' \\\n",
    "                                       % (emb_size, i, saturation, layer_size, drop, rate, epoch, j))\n",
    "                                NN = FF_Model(input_size=emb_size, layers=[layer_size], dropout=drop, learn_rate=rate)\n",
    "                                NN.build_graph()\n",
    "                                NN.train(sets, epochs=epoch)\n",
    "                                res = NN.predict(sets['test_set'])\n",
    "                                tru = np.argmax(sets['test_labels'], 1)\n",
    "                                perf = sk.metrics.f1_score(tru, res, pos_label=0)\n",
    "                                if perf > max_performance:\n",
    "                                    max_performance = perf\n",
    "                                    NN.save_model('gold')\n",
    "                                    model.save('gold/GOLDEMB')\n",
    "                                NN.close()\n",
    "                                n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sets = fn.get_traintest2(labelled_cases, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(sets['train_labels']).sum(0)/ len(sets['train_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.saturate_training_set(sets, model, target_dict['medications'], 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = NN.predict(sets['test_set'])\n",
    "tru = np.argmax(sets['test_labels'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp = len([a for a in range(len(tru)) if (res[a] == 0) and (tru[a] == 0)])\n",
    "tn = len([a for a in range(len(tru)) if (res[a] == 1) and (tru[a] == 1)])\n",
    "fp = len([a for a in range(len(tru)) if (res[a] == 0) and (tru[a] == 1)])\n",
    "fn = len([a for a in range(len(tru)) if (res[a] == 1) and (tru[a] == 0)])\n",
    "tp, tn, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sk.metrics.f1_score(tru, res, pos_label=0, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[(sets['test_words'][a], res[a], tru[a]) for a in range(len(sets['test_words'])) if res[a] == 1 and tru[a] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba = []\n",
    "for i in range(len(res)):\n",
    "    if not (sets['test_words'][i] == ')' or sets['test_words'][i] == '('):\n",
    "        proba.append([sets['test_words'][i], res[i], tru[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sk.metrics.f1_score(np.array(proba)[:,2].astype(int), np.array(proba)[:,1].astype(int), pos_label=0, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len([(proba[a][0], proba[a][1], proba[a][2]) for a in range(len(proba)) if proba[a][1] == 1 and proba[a][2] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[(proba[a][0], proba[a][1], proba[a][2]) for a in range(len(proba)) if proba[a][1] == 1 and proba[a][2] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'projectile' in target_dict['medications']"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
