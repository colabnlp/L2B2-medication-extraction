{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "import re\n",
    "import random\n",
    "\n",
    "import Functions as fn\n",
    "from DS import DS\n",
    "from Set import Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696/696 added from 2009 Medication Challenge/training.sets.released/\n",
      "553/1249 added from 2009 Medication Challenge/test.released.8.17.09/\n",
      "398/398 added from //smokers_surrogate_train_all_version2.xml\n",
      "104/104 added from //smokers_surrogate_test_all_groundtruth_version2.xml\n",
      "0/398 added from /1C smokers_surrogate_train_all_version2.zip/smokers_surrogate_train_all_version2.xml\n",
      "0/104 added from /1C smokers_surrogate_test_all_version2.zip/smokers_surrogate_test_all_version2.xml\n",
      "0/104 added from /1C smokers_surrogate_test_all_groundtruth_version2.zip/smokers_surrogate_test_all_groundtruth_version2.xml\n",
      "91/220 added from /1B deid_surrogate_test_all_version2.zip/deid_surrogate_test_all_version2.xml\n",
      "2/669 added from /1B deid_surrogate_train_all_version2_CORRECTED.zip/deid_surrogate_train_all_version2.xml\n",
      "331/889 added from /1A unannotated_records_deid_smoking_CORRECTED.zip/unannotated_records_deid_smoking.xml\n",
      "507/507 added from 2008 Obesity Challenge/obesity_patient_records_test.xml\n",
      "30/30 added from 2008 Obesity Challenge/obesity_patient_records_training 50.xml\n",
      "581/611 added from 2008 Obesity Challenge/obesity_patient_records_training.xml\n",
      "119/119 added from 2008 Obesity Challenge/obesity_patient_records_training2.xml\n",
      "73/73 added from 2010 Relations Challenge/concept_assertion_relation_training_data/beth/txt/\n",
      "97/97 added from 2010 Relations Challenge/concept_assertion_relation_training_data/partners/txt/\n",
      "267/267 added from 2010 Relations Challenge/concept_assertion_relation_training_data/partners/unannotated/\n",
      "3/3 added from 2010 Relations Challenge/Sample Data/\n",
      "254/256 added from 2010 Relations Challenge/test_data/\n",
      "76/79 added from 2011 Coreference Challenge/Test_Beth/docs/\n",
      "0/94 added from 2011 Coreference Challenge/Test_Partners/docs/\n",
      "112/115 added from 2011 Coreference Challenge/Train_Beth/docs/\n",
      "0/136 added from 2011 Coreference Challenge/Train_Partners/docs/\n",
      "191/191 added from 2012 Temporal Relations Challenge/Training Full_2012-07-15.original-annotation.release/\n",
      "119/120 added from 2012 Temporal Relations Challenge/Evaluation_Test TIMEX groundtruth_2012-08-08.test-data.event-timex-groundtruth/i2b2/\n",
      "0/120 added from 2012 Temporal Relations Challenge/Evaluation_Test ground_truth_2012-08-23.test-data.groundtruth/merged_i2b2/\n",
      "0/120 added from 2012 Temporal Relations Challenge/Evaluation_Test ground_truth_2012-08-23.test-data.groundtruth/unmerged_i2b2/\n",
      "1/120 added from 2012 Temporal Relations Challenge/Evaluation_Test data_2012-08-06.test-data-release/txt/\n"
     ]
    }
   ],
   "source": [
    "Dataset = fn.firstTimeLoad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Texts:  4605\n",
      "Number of 2007 Smoking Challenge texts:  926\n",
      "Number of 2008 ObesityChallenge texts:  1237\n",
      "Number of 2009 Medication Challenge texts:  1249\n",
      "Number of 2010 Relations Challenge texts:  694\n",
      "Number of 2011 Coreference Challenge texts:  188\n",
      "Number of 2012 Temporal Relations Challenge texts:  311\n",
      "Number of Train Texts:  2859\n",
      "Number of Test Texts:  1746\n",
      "Number of Labeled Texts:  258\n",
      "Number of Initially Labeled Texts:  10\n",
      "Number of Competitor Labeled Texts Texts:  248\n"
     ]
    }
   ],
   "source": [
    "print('Number of Texts: ', Dataset.size)\n",
    "print('Number of 2007 Smoking Challenge texts: ', Dataset.numberOf(challenge='2007 Smoking Challenge'))\n",
    "print('Number of 2008 ObesityChallenge texts: ', Dataset.numberOf(challenge='2008 Obesity Challenge'))\n",
    "print('Number of 2009 Medication Challenge texts: ', Dataset.numberOf(challenge='2009 Medication Challenge'))\n",
    "print('Number of 2010 Relations Challenge texts: ', Dataset.numberOf(challenge='2010 Relations Challenge'))\n",
    "print('Number of 2011 Coreference Challenge texts: ', Dataset.numberOf(challenge='2011 Coreference Challenge'))\n",
    "print('Number of 2012 Temporal Relations Challenge texts: ', Dataset.numberOf(challenge='2012 Temporal Relations Challenge'))\n",
    "print('Number of Train Texts: ', Dataset.numberOf(stage='train'))\n",
    "print('Number of Test Texts: ', Dataset.numberOf(stage='test'))\n",
    "print('Number of Labeled Texts: ', Dataset.numberOf(labelled='yes'))\n",
    "print('Number of Initially Labeled Texts: ', Dataset.numberOf(labelled='yes', label_type='train'))\n",
    "print('Number of Competitor Labeled Texts Texts: ', Dataset.numberOf(labelled='yes', label_type='test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_text Write Complete\n"
     ]
    }
   ],
   "source": [
    "Dataset.writeTexts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_labels Write Complete\n"
     ]
    }
   ],
   "source": [
    "Dataset.writeLabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.processForEmbedding()\n",
    "sentences = Dataset.getSentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medications = []\n",
    "labelled = Dataset.getDS(labelled='yes')\n",
    "\n",
    "for case in labelled.data:\n",
    "    for term in re.finditer(r'm=\"[a-z0-9 ]+\"', case.raw_labels):\n",
    "        temp = term.group()[3:-1]\n",
    "        temp = temp.split()\n",
    "        for word in temp:\n",
    "            if word not in medications:\n",
    "                medications.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_I2B2 = Word2Vec(sentences, min_count=1, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_I2B2.most_similar(\"timolol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = np.zeros(10)\n",
    "for med in medications:\n",
    "    num[len(med.split())] += 1\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "words = []\n",
    "for sent in sentences:\n",
    "    for word in sent:\n",
    "        words.append(word)\n",
    "\n",
    "cnt = Counter(words).most_common(1000)\n",
    "cnt = np.array(cnt)\n",
    "topwords = np.ndarray.tolist(cnt[:,0])\n",
    "len(topwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation = []\n",
    "\n",
    "for word in medications:\n",
    "    if word in model_I2B2.wv.vocab.keys():\n",
    "        visualisation.append(word)\n",
    "\n",
    "colormap = np.full(len(visualisation), \"red\")\n",
    "\n",
    "for word in topwords:\n",
    "    if not word in visualisation:\n",
    "        visualisation.append(word)\n",
    "        colormap = np.append(colormap, [\"blue\"])\n",
    "\n",
    "\n",
    "# This assumes words_top_ted is a list of strings, the top 1000 words\n",
    "words_vec = model_I2B2[visualisation]\n",
    "\n",
    "print(len(visualisation))\n",
    "print(len(words_vec))\n",
    "print(len(colormap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "words_tsne = tsne.fit_transform(words_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"word2vec T-SNE for most common words\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x1=words_tsne[:,0],\n",
    "                                    x2=words_tsne[:,1],\n",
    "                                    names=visualisation,\n",
    "                                    coloring=colormap))\n",
    "\n",
    "p.scatter(x=\"x1\", y=\"x2\", color=\"coloring\", size=8, source=source)\n",
    "\n",
    "labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                  source=source, text_align='center')\n",
    "p.add_layout(labels)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_I2B2.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_I2B2.most_similar('lasix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'dilantin' in medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for case in Dataset.data:\n",
    "    path = 'C:/Users/lgligic/Desktop/Project/data_simplified/' + case.challenge + '/'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    f = open(path + case.name, 'w+')\n",
    "    f.write(case.raw_text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
