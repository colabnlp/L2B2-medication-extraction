{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "\n",
    "import Functions as fn\n",
    "from DS import DS\n",
    "from Set import pool\n",
    "from Iterator import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dataset = fn.first_time_load()\n",
    "#Dataset.write_texts()\n",
    "#Dataset.write_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts loaded\n",
      "Labels loaded\n"
     ]
    }
   ],
   "source": [
    "Dataset = pool()\n",
    "Dataset.load_texts()\n",
    "Dataset.load_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print('Number of Texts: ', Dataset.size)\n",
    "#print('Number of 2007 Smoking Challenge texts: ', Dataset.number_of(challenge='2007 Smoking Challenge'))\n",
    "#print('Number of 2008 ObesityChallenge texts: ', Dataset.number_of(challenge='2008 Obesity Challenge'))\n",
    "#print('Number of 2009 Medication Challenge texts: ', Dataset.number_of(challenge='2009 Medication Challenge'))\n",
    "#print('Number of 2010 Relations Challenge texts: ', Dataset.number_of(challenge='2010 Relations Challenge'))\n",
    "#print('Number of 2011 Coreference Challenge texts: ', Dataset.number_of(challenge='2011 Coreference Challenge'))\n",
    "#print('Number of 2012 Temporal Relations Challenge texts: ', Dataset.number_of(challenge='2012 Temporal Relations Challenge'))\n",
    "#print('Number of Train Texts: ', Dataset.number_of(stage='train'))\n",
    "#print('Number of Test Texts: ', Dataset.number_of(stage='test'))\n",
    "#print('Number of Labeled Texts: ', Dataset.number_of(labelled='yes'))\n",
    "#print('Number of Initially Labeled Texts: ', Dataset.number_of(labelled='yes', label_type='train'))\n",
    "#print('Number of Competitor Labeled Texts Texts: ', Dataset.number_of(labelled='yes', label_type='test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.process_for_embedding()\n",
    "sentences = Dataset.get_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luka\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load('W2V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = Word2Vec(sentences, min_count=1, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.most_similar(\"prozac\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of: m=928, do=119, mo=76, f=79, du=80, r=482\n"
     ]
    }
   ],
   "source": [
    "targets = ['medications', 'dosages', 'modes', 'frequencies', 'durations', 'reasons']\n",
    "target_dict = {label: words for (label, words) in zip(targets, list(fn.label_words(Dataset)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn.visualise(model, sentences, [target_dict['medications']], 1000, 'Medications in top 1000 words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_set = set()\n",
    "#for case in Dataset.get_DS(labelled='yes').data:\n",
    "#    for term in re.finditer(r'm=\"[a-z0-9 ]+\"', case.raw_labels):\n",
    "#        if term.group()[3:-1] != 'nm': print_set.add(term.group()[3:-1])\n",
    "#print(*print_set, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for target in targets:\n",
    "#    for reps in [True, False]:\n",
    "#        target_size = len(target_dict[target])\n",
    "#        sets = fn.get_traintest(model, target_dict[target], target_size * 5, target_size, 10, 50, reps, reps)\n",
    "#        fn.model_1(sets[0], sets[1], sets[2], sets[3], target=target, repetitions='yes' if reps else 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn.write_emb('testemb', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_model = fn.load_emb('testemb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save('W2V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelled_cases = Dataset.get_DS(labelled='yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labelled_cases.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in labelled_cases.data:\n",
    "    text = case.raw_text\n",
    "    text = text.split('\\n')\n",
    "    for i in range(len(text)):\n",
    "        text[i] = text[i].strip('.')\n",
    "        text[i] = re.sub(r'\\d+', '<NUM>', text[i])\n",
    "        text[i] = re.sub(r'([A-Za-z]):', r'\\1', text[i])\n",
    "        text[i] = re.sub(r'Dr.', 'Dr', text[i])\n",
    "        text[i] = re.sub(r'Mr.', 'Mr', text[i])\n",
    "        text[i] = re.sub(r'\\. ([A-Z])', r'. A\\1', text[i])\n",
    "        text[i] = re.sub(r'\\. [A-Z]', ' ', text[i])\n",
    "        text[i] = text[i].lower()\n",
    "        text[i] = text[i].split()\n",
    "    case.token_text = text\n",
    "    \n",
    "    indeces = []\n",
    "    for med in re.finditer(r'm=\"[^\"]*\" \\d+:\\d+ \\d+:\\d+', case.raw_labels):\n",
    "        indeces.append([[int(a) for a in b.split(':')] for b in med.group().split()[-2:]])\n",
    "    indeces.sort()\n",
    "    indeces.append([[0,0],[0,0]])\n",
    "    \n",
    "    truth = []\n",
    "    c = 0\n",
    "    inside =  False\n",
    "    for i in range(len(text)):\n",
    "        for j in range(len(text[i])):\n",
    "            if inside:\n",
    "                if i+1 < indeces[c][1][0]: truth.append([1,0])\n",
    "                elif i+1 == indeces[c][1][0]:\n",
    "                    if j < indeces[c][1][1]: truth.append([1,0])\n",
    "                    elif j == indeces[c][1][1]:\n",
    "                        truth.append([1,0])\n",
    "                        inside = False\n",
    "                        c += 1\n",
    "            else:\n",
    "                if [i+1, j] == indeces[c][0]:\n",
    "                    truth.append([1,0])\n",
    "                    if [i+1, j] == indeces[c][1]: c += 1\n",
    "                    else: inside = True\n",
    "                else: truth.append([0,1])\n",
    "    case.test_labels = truth\n",
    "    \n",
    "    case.test_text = [word for sentence in case.token_text for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 295 548\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(labelled_cases.data)):\n",
    "    if len(labelled_cases.data[i].test_labels) != len(labelled_cases.data[i].test_text):\n",
    "        print(i, len(labelled_cases.data[i].test_labels), len(labelled_cases.data[i].test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m=\"lantus ( insulin glargine )\" 17:0 17:4\n",
      "m=\"ranitidine hcl syrup\" 19:0 19:2\n",
      "m=\"roxicet elixir ( oxycodone+apap liquid )\" 20:0 20:5\n",
      "m=\"colace ( docusate sodium )\" 22:0 22:4\n",
      "m=\"phenergan ( promethazine hcl )\" 24:0 24:4\n",
      "m=\"augmentin susp. 250mg/62.5 mg ( 5ml ) ( amoxicil... )\" 25:0 25:9\n",
      "m=\"pca analgesia\" 51:11 51:12\n",
      "m=\"elixir analgesia\" 52:7 52:8\n",
      "m=\"roxicet\" 59:13 59:13\n",
      "m=\"qugmentin suspension\" 60:9 60:10\n",
      "m=\"ranitidine elixir\" 60:1 60:2\n",
      "m=\"previous home medications.\" 61:1 61:3\n",
      "m=\"lantus\" 63:4 63:4\n",
      "m=\"narcotic ( pain ) medications.\" 70:5 70:9\n",
      "[[[17, 0], [17, 4]], [[19, 0], [19, 2]], [[20, 0], [20, 5]], [[22, 0], [22, 4]], [[24, 0], [24, 4]], [[25, 0], [25, 9]], [[51, 11], [51, 12]], [[52, 7], [52, 8]], [[59, 13], [59, 13]], [[60, 1], [60, 2]], [[60, 9], [60, 10]], [[61, 1], [61, 3]], [[63, 4], [63, 4]], [[70, 5], [70, 9]], [[0, 0], [0, 0]]]\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "indeces = []\n",
    "for med in re.finditer(r'm=\"[^\"]*\" \\d+:\\d+ \\d+:\\d+', labelled_cases.data[240].raw_labels):\n",
    "    indeces.append([[int(a) for a in b.split(':')] for b in med.group().split()[-2:]])\n",
    "    print(med.group())\n",
    "indeces.sort()\n",
    "indeces.append([[0,0],[0,0]])\n",
    "print(indeces)\n",
    "print(len(indeces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m=\"lantus ( insulin glargine )\" 17:0 17:4||do=\"10 units\" 17:5 17:6||mo=\"sc\" 17:7 17:7||f=\"qd\" 17:8 17:8||du=\"nm\"||r=\"nm\"||ln=\"list\"\n",
      "m=\"ranitidine hcl syrup\" 19:0 19:2||do=\"150 mg\" 19:3 19:4||mo=\"po\" 19:5 19:5||f=\"bid\" 19:6 19:6||du=\"nm\"||r=\"nm\"||ln=\"list\"\n",
      "m=\"roxicet elixir ( oxycodone+apap liquid )\" 20:0 20:5||do=\"5-10 milliliters\" 21:0 21:1||mo=\"po\" 21:2 21:2||f=\"q4h prn\" 21:3 21:4||du=\"nm\"||r=\"pain\" 21:5 21:5||ln=\"list\"\n",
      "m=\"colace ( docusate sodium )\" 22:0 22:4||do=\"100 mg\" 22:5 22:6||mo=\"po\" 22:7 22:7||f=\"tid\" 22:8 22:8||du=\"nm\"||r=\"nm\"||ln=\"list\"\n",
      "m=\"phenergan ( promethazine hcl )\" 24:0 24:4||do=\"25 mg\" 24:5 24:6||mo=\"pr\" 24:7 24:7||f=\"q6h prn\" 24:8 24:9||du=\"nm\"||r=\"nausea\" 24:10 24:10||ln=\"list\"\n",
      "m=\"augmentin susp. 250mg/62.5 mg ( 5ml ) ( amoxicil... )\" 25:0 25:9||do=\"10 milliliters\" 26:0 26:1||mo=\"po\" 26:2 26:2||f=\"tid\" 26:3 26:3||du=\"for five days\" 26:5 26:7||r=\"nm\"||ln=\"list\"\n",
      "m=\"pca analgesia\" 51:11 51:12||do=\"nm\"||mo=\"nm\"||f=\"nm\"||du=\"nm\"||r=\"pain\" 51:6 51:6||ln=\"narrative\"\n",
      "m=\"elixir analgesia\" 52:7 52:8||do=\"nm\"||mo=\"po\" 52:6 52:6||f=\"nm\"||du=\"nm\"||r=\"nm\"||ln=\"narrative\"\n",
      "m=\"roxicet\" 59:13 59:13||do=\"nm\"||mo=\"nm\"||f=\"nm\"||du=\"nm\"||r=\"nm\"||ln=\"narrative\"\n",
      "m=\"qugmentin suspension\" 60:9 60:10||do=\"nm\"||mo=\"nm\"||f=\"nm\"||du=\"nm\"||r=\"nm\"||ln=\"narrative\"\n",
      "m=\"ranitidine elixir\" 60:1 60:2||do=\"nm\"||mo=\"nm\"||f=\"nm\"||du=\"nm\"||r=\"nm\"||ln=\"narrative\"\n",
      "m=\"previous home medications.\" 61:1 61:3||do=\"nm\"||mo=\"nm\"||f=\"nm\"||du=\"nm\"||r=\"nm\"||ln=\"narrative\"\n",
      "m=\"lantus\" 63:4 63:4||do=\"nm\"||mo=\"nm\"||f=\"nm\"||du=\"nm\"||r=\"her diabetes\" 62:4 62:5||ln=\"narrative\"\n",
      "m=\"narcotic ( pain ) medications.\" 70:5 70:9||do=\"nm\"||mo=\"nm\"||f=\"nm\"||du=\"nm\"||r=\"nm\"||ln=\"narrative\"\n",
      "\n",
      "15\n",
      "Name:  1222\n",
      "Challenge:  2009 Medication Challenge\n",
      "Train or Test Set:  test\n",
      "Labelled:  yes\n",
      "Labeling Type:  test\n"
     ]
    }
   ],
   "source": [
    "print(labelled_cases.data[240].raw_labels)\n",
    "print(len(labelled_cases.data[240].raw_labels.split('\\n')))\n",
    "labelled_cases.data[240].show_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "print([labelled_cases.data[n].test_text[a] for a in range(len(labelled_cases.data[n].test_text)) if labelled_cases.data[n].test_labels[a] == [1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [model[word] if word in model.wv.vocab else np.zeros(100) for case in labelled_cases.data[:230] for word in case.test_text]\n",
    "train_labels = [label for case in labelled_cases.data[:230] for label in case.test_labels] \n",
    "test_set = [model[word] if word in model.wv.vocab else np.zeros(100) for case in labelled_cases.data[230:] for word in case.test_text]\n",
    "test_labels = [label for case in labelled_cases.data[230:] for label in case.test_labels]\n",
    "\n",
    "test_words = [word for case in labelled_cases.data[230:] for word in case.test_text]\n",
    "print(*[len(a) for a in [train_set, train_labels, test_set, test_labels, test_words]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*map(len, [train_set, train_labels, test_set, test_labels, test_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(train_labels).sum(0)/ len(train_labels))\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (np.array(train_labels).sum(0)/ len(train_labels))[0] < 0.5:\n",
    "    for med in target_dict['medications']:\n",
    "        train_set.append(model_I2B2[med])\n",
    "        train_labels.append([1,0])\n",
    "    print(np.array(train_labels).sum(0)/len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(train_labels).sum(0)/ len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_count = 10\n",
    "input_size = 100\n",
    "output_size = 2\n",
    "batch_size = 50\n",
    "epochs = 10\n",
    "report_percentage = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.05)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(0.1, shape=shape)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    node_count = node_count\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, input_size])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, output_size])\n",
    "\n",
    "    # Define the first layer here\n",
    "    W = weight_variable([input_size, node_count])\n",
    "    b = bias_variable([node_count])\n",
    "    h = tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "\n",
    "    # Use dropout for this layer (should you wish)\n",
    "    # keep_prob = tf.placeholder(tf.float32)\n",
    "    # h_drop = tf.nn.dropout(h1, keep_prob)\n",
    "\n",
    "    # Define the second layer here\n",
    "    # W2 = weight_variable([node_count_1, node_count_2])\n",
    "    # b2 = bias_variable([node_count_2])\n",
    "    # h2 = tf.nn.sigmoid(tf.matmul(h, W) + b)\n",
    "\n",
    "    # Define the output layer here\n",
    "    V = weight_variable([node_count, output_size])\n",
    "    c = bias_variable([output_size])\n",
    "    y = tf.nn.softmax(tf.matmul(h, V) + c)\n",
    "\n",
    "    # We'll use the cross entropy loss function\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "\n",
    "    # And classification accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    # And the Adam optimiser\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(cross_entropy)\n",
    "\n",
    "    # Start a tf session and run the optimisation algorithm\n",
    "    sess = tf.Session()\n",
    "    # sess.run(tf.initialize_all_variables())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    training = Iterator(train_set, train_labels)\n",
    "    mark = (epochs * (len(train_set) // batch_size) * report_percentage) // 100\n",
    "    N = 0\n",
    "\n",
    "    #print(\"Target: %s \\tRepetitions: %s\" % (target, repetitions))\n",
    "    while training.epochs < epochs:\n",
    "        trd, trl = training.next_batch(batch_size)\n",
    "        if N % mark == 0:\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={x: trd, y_: trl})\n",
    "            test_accuracy = sess.run(accuracy, feed_dict={x: test_set, y_: test_labels})\n",
    "            print(\"Progress: %d%% \\tTraining Accuracy: %f\\t Test accuracy: %f\" % (N * report_percentage// mark, train_accuracy, test_accuracy))\n",
    "        sess.run(train_step, feed_dict={x: trd, y_: trl})\n",
    "        N += 1\n",
    "\n",
    "    print(\"Final Test Accuracy: %f\\n\" % (sess.run(accuracy, feed_dict={x: test_set, y_: test_labels})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.argmax(y, 1)\n",
    "res = sess.run(pred, feed_dict={x: test_set, y_:test_labels})\n",
    "tru = np.argmax(test_labels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk.metrics.f1_score(tru, res, pos_label=0, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_words = [word for word in case.test_text for case in labelled_cases.data[230:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[(test_words[a], res[a], tru[a]) for a in [i*28] if res[a] == 1 and tru[a] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([a for a in res if a == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk.metrics.f1_score(tru, res, pos_label=0, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(example_text_5[a], res[a], tru[a]) for a in range(len(example_text_5)) if res[a] == 0 and tru[a] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = len([a for a in range(len(tru)) if (res[a] == 0) and (tru[a] == 0)])\n",
    "tn = len([a for a in range(len(tru)) if (res[a] == 1) and (tru[a] == 1)])\n",
    "fp = len([a for a in range(len(tru)) if (res[a] == 0) and (tru[a] == 1)])\n",
    "fn = len([a for a in range(len(tru)) if (res[a] == 1) and (tru[a] == 0)])\n",
    "tp, tn, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((2*tp)/(2*tp + fn +fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
