{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "\n",
    "import Functions as fn\n",
    "from DS import DS\n",
    "from Set import pool\n",
    "from Iterator import Iterator\n",
    "from FFModel import FF_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Text Load Complete\n",
      "Raw Labels Load Complete\n"
     ]
    }
   ],
   "source": [
    "Dataset = pool()\n",
    "Dataset.load_texts('raw_texts')\n",
    "Dataset.load_labels('raw_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print('Number of Texts: ', Dataset.size)\n",
    "#print('Number of 2007 Smoking Challenge texts: ', Dataset.number_of(challenge='2007 Smoking Challenge'))\n",
    "#print('Number of 2008 ObesityChallenge texts: ', Dataset.number_of(challenge='2008 Obesity Challenge'))\n",
    "#print('Number of 2009 Medication Challenge texts: ', Dataset.number_of(challenge='2009 Medication Challenge'))\n",
    "#print('Number of 2010 Relations Challenge texts: ', Dataset.number_of(challenge='2010 Relations Challenge'))\n",
    "#print('Number of 2011 Coreference Challenge texts: ', Dataset.number_of(challenge='2011 Coreference Challenge'))\n",
    "#print('Number of 2012 Temporal Relations Challenge texts: ', Dataset.number_of(challenge='2012 Temporal Relations Challenge'))\n",
    "#print('Number of Train Texts: ', Dataset.number_of(stage='train'))\n",
    "#print('Number of Test Texts: ', Dataset.number_of(stage='test'))\n",
    "#print('Number of Labeled Texts: ', Dataset.number_of(labelled='yes'))\n",
    "#print('Number of Initially Labeled Texts: ', Dataset.number_of(labelled='yes', label_type='train'))\n",
    "#print('Number of Competitor Labeled Texts Texts: ', Dataset.number_of(labelled='yes', label_type='test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Load Complete\n"
     ]
    }
   ],
   "source": [
    "target_dict = fn.load_labels('labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lgligic\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Load Complete\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = fn.load_sentences('sent')\n",
    "#model = Word2Vec(sentences, min_count=1, size=100)\n",
    "\n",
    "model = Word2Vec.load('W2V')\n",
    "vocab = model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.most_similar(\"prozac\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn.visualise(model, sentences, [target_dict['medications']], 1000, 'Medications in top 1000 words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print_set = []\n",
    "#for case in Dataset.get_DS(labelled='yes').data:\n",
    "#    for term in re.finditer(r'm=\"[^|]+\\|', case.raw_labels):\n",
    "#        print_set.append(term.group()[:-1])\n",
    "#print(*print_set, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: medications \tRepetitions: True\n",
      "FInal Values: TrAcc: 0.968646, ValAcc: 0.788839, ValF1: 0.736347\n",
      "Test F1-Score: 0.737535\n",
      "\n",
      "Target: medications \tRepetitions: False\n",
      "FInal Values: TrAcc: 0.963069, ValAcc: 0.777526, ValF1: 0.720379\n",
      "Test F1-Score: 0.720379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for target in ['medications']:\n",
    "    for reps in [True, False]:\n",
    "        target_size = len(target_dict[target])\n",
    "        word_sets = fn.get_naive_traintest(vocab, target_dict[target], target_size * 5, target_size, 10, 50, reps, reps)\n",
    "        emb_sets = fn.embed_words(word_sets, model)\n",
    "        emb_sets['validation_set'] = emb_sets['test_set']\n",
    "        emb_sets['validation_labels'] = emb_sets['test_labels']\n",
    "        print(\"Target: %s \\tRepetitions: %s\" % (target, reps))\n",
    "        NN = FF_Model()\n",
    "        NN.build_graph()\n",
    "        NN.train(emb_sets, epochs=50, report_percentage=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_sizes = [5, 10,]\n",
    "emb_num = 1\n",
    "NN_num = 3\n",
    "model_num = emb_num * NN_num * len(emb_sizes)\n",
    "\n",
    "target = target_dict['medications']\n",
    "\n",
    "layers = [50]\n",
    "dropout = 1.0\n",
    "learn_rate = 0.01\n",
    "\n",
    "epochs = 50\n",
    "batch = 50\n",
    "report_percentage = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sets = fn.get_naive_traintest(vocab=vocab,\n",
    "                                   labels=target,\n",
    "                                   train_size=10000,\n",
    "                                   test_size=1000,\n",
    "                                   train_label_percentage=10,\n",
    "                                   test_label_percentage=10,\n",
    "                                   word_repetition = True,\n",
    "                                   label_repetition = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 1/6 (EmbSize: 5, EmbMod: 0/1, NN: 0/3)\n",
      "FInal Values: TrAcc: 0.9419, ValAcc: 0.934, ValF1: 0.616279\n",
      "Test F1-Score: 0.619883\n",
      "\n",
      "Model Number: 2/6 (EmbSize: 5, EmbMod: 0/1, NN: 1/3)\n",
      "FInal Values: TrAcc: 0.9422, ValAcc: 0.936, ValF1: 0.619048\n",
      "Test F1-Score: 0.619048\n",
      "\n",
      "Model Number: 3/6 (EmbSize: 5, EmbMod: 0/1, NN: 2/3)\n",
      "FInal Values: TrAcc: 0.9406, ValAcc: 0.935, ValF1: 0.615385\n",
      "Test F1-Score: 0.615385\n",
      "\n",
      "Model Number: 4/6 (EmbSize: 10, EmbMod: 0/1, NN: 0/3)\n",
      "FInal Values: TrAcc: 0.9518, ValAcc: 0.935, ValF1: 0.615385\n",
      "Test F1-Score: 0.615385\n",
      "\n",
      "Model Number: 5/6 (EmbSize: 10, EmbMod: 0/1, NN: 1/3)\n",
      "FInal Values: TrAcc: 0.9523, ValAcc: 0.936, ValF1: 0.627907\n",
      "Test F1-Score: 0.627907\n",
      "\n",
      "Model Number: 6/6 (EmbSize: 10, EmbMod: 0/1, NN: 2/3)\n",
      "FInal Values: TrAcc: 0.9513, ValAcc: 0.94, ValF1: 0.647059\n",
      "Test F1-Score: 0.647059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "results = []\n",
    "for emb_size in emb_sizes:\n",
    "    average = 0\n",
    "    for i in range(emb_num):\n",
    "        model = Word2Vec(sentences, min_count=1, size=emb_size)\n",
    "        emb_sets = fn.embed_words(word_sets, model)\n",
    "        emb_sets['validation_set'] = emb_sets['test_set']\n",
    "        emb_sets['validation_labels'] = emb_sets['test_labels']\n",
    "        for j in range(NN_num):\n",
    "            n += 1\n",
    "            print('Model Number: %d/%d (EmbSize: %d, EmbMod: %d/%d, NN: %d/%d)' % (n, model_num, emb_size, i+1, emb_num, j+1, NN_num))\n",
    "            NN = FF_Model(input_size=emb_size, layers=layers, dropout=dropout, learn_rate=learn_rate)\n",
    "            NN.build_graph()\n",
    "            _, _, _, score = NN.train(emb_sets, epochs=epochs, batch=batch, report_percentage=10)\n",
    "            average += score\n",
    "    results.append(average / (emb_num * NN_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:\tPerf:\n",
      "5\t0.618105\n",
      "10\t0.630117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Size:\\tPerf:')\n",
    "[print('%g\\t%g' % (a, b)) for a, b in zip(emb_sizes, results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
