{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luka\\anaconda3\\envs\\tensorflow13\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import Functions as fn\n",
    "import Iterator as it\n",
    "from DS import DS\n",
    "from Set import pool\n",
    "from FFModel import FF_Model\n",
    "from RNNModel import RNN_Model\n",
    "from S2SModel import S2S_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Text Load Complete\n",
      "Raw Labels Load Complete\n"
     ]
    }
   ],
   "source": [
    "Dataset = pool()\n",
    "Dataset.load_texts('raw_texts')\n",
    "Dataset.load_labels('raw_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Load Complete\n"
     ]
    }
   ],
   "source": [
    "target_dict = fn.load_labels('final_meta/labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4585 238 10 10\n"
     ]
    }
   ],
   "source": [
    "train_set = pool(data=(Dataset.get_DS(stage='test', labelled='yes')).data[:-10])\n",
    "validation_set = pool(data=(Dataset.get_DS(stage='test', labelled='yes')).data[-10:])\n",
    "test_set = Dataset.get_DS(stage='train', labelled='yes')\n",
    "set_1 = Dataset.get_DS(stage='train', labelled='no')\n",
    "set_2 = Dataset.get_DS(stage='test', labelled='no')\n",
    "set_1.append(set_2.data)\n",
    "set_1.append(train_set.data)\n",
    "emb_set = set_1\n",
    "print(emb_set.size, train_set.size, validation_set.size, test_set.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Load Complete\n"
     ]
    }
   ],
   "source": [
    "#emb_set.process_for_embedding()\n",
    "#sentences = emb_set.get_sentences()\n",
    "#fn.write_sentences(sentences, 'final_meta/sentences')\n",
    "sentences = fn.load_sentences('final_meta/sentences')\n",
    "\n",
    "#model = Word2Vec(sentences, min_count=1, size=100)\n",
    "#model.save('final_meta/W2V')\n",
    "model = Word2Vec.load('final_meta/W2V')\n",
    "\n",
    "vocab = model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer and Index Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Indices Load Complete\n",
      "Embedding Layer Load Complete\n"
     ]
    }
   ],
   "source": [
    "#word_indices, emb_layer = fn.get_index_and_emb_layer(model)\n",
    "#fn.write_word_indices(word_indices, 's2s/word_indices')\n",
    "#fn.write_emb_layer(emb_layer, 's2s/emb_layer')\n",
    "\n",
    "word_indices = fn.load_word_indices('s2s/word_indices')\n",
    "emb_layer = fn.load_emb_layer('s2s/emb_layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDS2S Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set.process_for_s2s_testing()\n",
    "validation_set.process_for_s2s_testing()\n",
    "test_set.process_for_s2s_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 34\n"
     ]
    }
   ],
   "source": [
    "max_enc_inp = 0\n",
    "max_dec_inp = 0\n",
    "for setin in [train_set, validation_set, test_set]:\n",
    "    for case in setin.data:\n",
    "        for enc_inp  in case.enc_inputs:\n",
    "            max_enc_inp = max(max_enc_inp, len(enc_inp))\n",
    "        for dec_inp  in case.dec_inputs:\n",
    "            max_dec_inp = max(max_dec_inp, len(dec_inp))\n",
    "print(max_enc_inp, max_dec_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sets = {}\n",
    "sets['train'] = train_set.get_s2s_sets(word_indices, max_enc_inp, max_dec_inp)\n",
    "sets['validation'] = validation_set.get_s2s_sets(word_indices, max_enc_inp, max_dec_inp)\n",
    "sets['test'] = test_set.get_s2s_sets(word_indices, max_enc_inp, max_dec_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Learn Rate: 0.0010000, Perplexity: 1811.32\n",
      "Epoch: 1, Learn Rate: 0.0010000, Perplexity: 22.05\n",
      "Epoch: 2, Learn Rate: 0.0009984, Perplexity: 10.23\n",
      "Epoch: 3, Learn Rate: 0.0009952, Perplexity: 6.85\n",
      "Epoch: 4, Learn Rate: 0.0009905, Perplexity: 4.18\n",
      "Epoch: 5, Learn Rate: 0.0009842, Perplexity: 4.72\n",
      "Epoch: 6, Learn Rate: 0.0009764, Perplexity: 3.56\n",
      "Epoch: 7, Learn Rate: 0.0009672, Perplexity: 2.99\n",
      "Epoch: 8, Learn Rate: 0.0009565, Perplexity: 2.27\n",
      "Epoch: 9, Learn Rate: 0.0009444, Perplexity: 2.14\n",
      "Epoch: 10, Learn Rate: 0.0009310, Perplexity: 2.44\n",
      "Epoch: 11, Learn Rate: 0.0009163, Perplexity: 2.12\n",
      "Epoch: 12, Learn Rate: 0.0009004, Perplexity: 1.62\n",
      "Epoch: 13, Learn Rate: 0.0008834, Perplexity: 1.56\n",
      "Epoch: 14, Learn Rate: 0.0008653, Perplexity: 1.49\n",
      "Epoch: 15, Learn Rate: 0.0008462, Perplexity: 1.34\n",
      "Epoch: 16, Learn Rate: 0.0008263, Perplexity: 1.38\n",
      "Epoch: 17, Learn Rate: 0.0008056, Perplexity: 1.34\n",
      "Epoch: 18, Learn Rate: 0.0007841, Perplexity: 1.21\n",
      "Epoch: 19, Learn Rate: 0.0007620, Perplexity: 1.30\n",
      "Epoch: 20, Learn Rate: 0.0007393, Perplexity: 1.20\n",
      "Epoch: 21, Learn Rate: 0.0007161, Perplexity: 1.17\n",
      "Epoch: 22, Learn Rate: 0.0006926, Perplexity: 1.13\n",
      "Epoch: 23, Learn Rate: 0.0006688, Perplexity: 1.07\n",
      "Epoch: 24, Learn Rate: 0.0006448, Perplexity: 1.17\n",
      "Epoch: 25, Learn Rate: 0.0006207, Perplexity: 1.15\n",
      "Epoch: 26, Learn Rate: 0.0005965, Perplexity: 1.05\n",
      "Epoch: 27, Learn Rate: 0.0005723, Perplexity: 1.11\n",
      "Epoch: 28, Learn Rate: 0.0005483, Perplexity: 1.16\n",
      "Epoch: 29, Learn Rate: 0.0005244, Perplexity: 1.09\n",
      "Epoch: 30, Learn Rate: 0.0005008, Perplexity: 1.04\n",
      "Epoch: 31, Learn Rate: 0.0004775, Perplexity: 1.10\n",
      "Epoch: 32, Learn Rate: 0.0004545, Perplexity: 1.02\n",
      "Epoch: 33, Learn Rate: 0.0004320, Perplexity: 1.03\n",
      "Epoch: 34, Learn Rate: 0.0004099, Perplexity: 1.09\n",
      "Epoch: 35, Learn Rate: 0.0003883, Perplexity: 1.02\n",
      "Epoch: 36, Learn Rate: 0.0003673, Perplexity: 1.03\n",
      "Epoch: 37, Learn Rate: 0.0003469, Perplexity: 1.08\n",
      "Epoch: 38, Learn Rate: 0.0003271, Perplexity: 1.03\n",
      "Epoch: 39, Learn Rate: 0.0003079, Perplexity: 1.02\n",
      "Epoch: 40, Learn Rate: 0.0002894, Perplexity: 1.04\n",
      "Epoch: 41, Learn Rate: 0.0002715, Perplexity: 1.02\n",
      "Epoch: 42, Learn Rate: 0.0002544, Perplexity: 1.01\n",
      "Epoch: 43, Learn Rate: 0.0002380, Perplexity: 1.01\n",
      "Epoch: 44, Learn Rate: 0.0002223, Perplexity: 1.01\n",
      "Epoch: 45, Learn Rate: 0.0002072, Perplexity: 1.01\n",
      "Epoch: 46, Learn Rate: 0.0001929, Perplexity: 1.03\n",
      "Epoch: 47, Learn Rate: 0.0001793, Perplexity: 1.03\n",
      "Epoch: 48, Learn Rate: 0.0001664, Perplexity: 1.01\n",
      "Epoch: 49, Learn Rate: 0.0001542, Perplexity: 1.03\n",
      "Epoch: 50, Learn Rate: 0.0001426, Perplexity: 1.01\n",
      "Epoch: 51, Learn Rate: 0.0001317, Perplexity: 1.03\n",
      "Epoch: 52, Learn Rate: 0.0001215, Perplexity: 1.03\n",
      "Epoch: 53, Learn Rate: 0.0001118, Perplexity: 1.01\n",
      "Epoch: 54, Learn Rate: 0.0001028, Perplexity: 1.02\n",
      "Epoch: 55, Learn Rate: 0.0000944, Perplexity: 1.01\n",
      "Epoch: 56, Learn Rate: 0.0000865, Perplexity: 1.01\n",
      "Epoch: 57, Learn Rate: 0.0000791, Perplexity: 1.07\n",
      "Epoch: 58, Learn Rate: 0.0000722, Perplexity: 1.01\n",
      "Epoch: 59, Learn Rate: 0.0000659, Perplexity: 1.01\n",
      "Epoch: 60, Learn Rate: 0.0000600, Perplexity: 1.04\n",
      "Epoch: 61, Learn Rate: 0.0000545, Perplexity: 1.01\n",
      "Epoch: 62, Learn Rate: 0.0000495, Perplexity: 1.04\n",
      "Epoch: 63, Learn Rate: 0.0000448, Perplexity: 1.02\n",
      "Epoch: 64, Learn Rate: 0.0000406, Perplexity: 1.01\n",
      "Epoch: 65, Learn Rate: 0.0000366, Perplexity: 1.01\n",
      "Epoch: 66, Learn Rate: 0.0000330, Perplexity: 1.01\n",
      "Epoch: 67, Learn Rate: 0.0000298, Perplexity: 1.00\n",
      "Epoch: 68, Learn Rate: 0.0000268, Perplexity: 1.02\n",
      "Epoch: 69, Learn Rate: 0.0000240, Perplexity: 1.01\n",
      "Epoch: 70, Learn Rate: 0.0000215, Perplexity: 1.01\n",
      "Epoch: 71, Learn Rate: 0.0000193, Perplexity: 1.01\n",
      "Epoch: 72, Learn Rate: 0.0000172, Perplexity: 1.01\n",
      "Epoch: 73, Learn Rate: 0.0000153, Perplexity: 1.00\n",
      "Epoch: 74, Learn Rate: 0.0000137, Perplexity: 1.01\n",
      "Epoch: 75, Learn Rate: 0.0000121, Perplexity: 1.06\n",
      "Epoch: 76, Learn Rate: 0.0000108, Perplexity: 1.02\n",
      "Epoch: 77, Learn Rate: 0.0000096, Perplexity: 1.01\n",
      "Epoch: 78, Learn Rate: 0.0000085, Perplexity: 1.01\n",
      "Epoch: 79, Learn Rate: 0.0000075, Perplexity: 1.01\n",
      "Epoch: 80, Learn Rate: 0.0000066, Perplexity: 1.00\n",
      "Epoch: 81, Learn Rate: 0.0000058, Perplexity: 1.08\n",
      "Epoch: 82, Learn Rate: 0.0000051, Perplexity: 1.03\n",
      "Epoch: 83, Learn Rate: 0.0000045, Perplexity: 1.00\n",
      "Epoch: 84, Learn Rate: 0.0000039, Perplexity: 1.00\n",
      "Epoch: 85, Learn Rate: 0.0000034, Perplexity: 1.02\n",
      "Epoch: 86, Learn Rate: 0.0000030, Perplexity: 1.01\n",
      "Epoch: 87, Learn Rate: 0.0000026, Perplexity: 1.00\n",
      "Epoch: 88, Learn Rate: 0.0000023, Perplexity: 1.02\n",
      "Epoch: 89, Learn Rate: 0.0000020, Perplexity: 1.00\n",
      "Epoch: 90, Learn Rate: 0.0000017, Perplexity: 1.00\n",
      "Epoch: 91, Learn Rate: 0.0000015, Perplexity: 1.02\n",
      "Epoch: 92, Learn Rate: 0.0000013, Perplexity: 1.00\n",
      "Epoch: 93, Learn Rate: 0.0000011, Perplexity: 1.04\n",
      "Epoch: 94, Learn Rate: 0.0000010, Perplexity: 1.03\n",
      "Epoch: 95, Learn Rate: 0.0000008, Perplexity: 1.01\n",
      "Epoch: 96, Learn Rate: 0.0000007, Perplexity: 1.01\n",
      "Epoch: 97, Learn Rate: 0.0000006, Perplexity: 1.00\n",
      "Epoch: 98, Learn Rate: 0.0000005, Perplexity: 1.00\n",
      "Epoch: 99, Learn Rate: 0.0000004, Perplexity: 1.00\n",
      "Epoch: 100, Learn Rate: 0.0000004, Perplexity: 1.01\n",
      "Progress: 100%\r"
     ]
    }
   ],
   "source": [
    "S2S = S2S_Model(decay = 0.00001,\n",
    "                batch=50,\n",
    "                enc_vocab_size=len(word_indices), \n",
    "                dec_vocab_size=len(word_indices), \n",
    "                enc_emb_size=100, \n",
    "                dec_emb_size=100, \n",
    "                state_size=128, \n",
    "                dropout=1.0,\n",
    "                learn_rate=0.001,\n",
    "                max_gradient_norm=5,\n",
    "                enc_emb_layer=emb_layer)\n",
    "S2S.build_graph()\n",
    "S2S.train(sets=sets, epochs=100, report_percentage=1, show_progress=True, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tru_vocab = []\n",
    "tru_words = sets['test'][7]\n",
    "for i in range(len(sets['test'][5])):\n",
    "    tru_vocab.append(sets['test'][5][i][:sets['test'][4][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(len(sets['test'][0])):\n",
    "    dummy = [[], [], [], [], [], [], []]\n",
    "    for j in range(50):\n",
    "        for k in range(7):\n",
    "            dummy[k].append(sets['test'][k][i])\n",
    "    temp = S2S.predict(dummy)\n",
    "    res.append(temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_vocab = res\n",
    "res_words = []\n",
    "for case in res_vocab:\n",
    "    temp = []\n",
    "    for index in case:\n",
    "        for word in word_indices:\n",
    "            if word_indices[word] == index:\n",
    "                temp.append(word)\n",
    "    res_words.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ofloxacin', '<num>', 'mg', 'po', 'q', '<num>', '<eos>']\n",
      "['ofloxacin', '<num>', 'mg', 'po', 'q', '<num>', '<eos>']\n",
      "['insulin', 'nph', '<num>', 'units', 'subcu', 'bid', '<eos>']\n",
      "['insulin', 'nph', '<num>', 'units', 'subcu', 'bid', '<eos>']\n",
      "['colace', '<num>', 'mg', 'po', 'bid', '<eos>']\n",
      "['colace', '<num>', 'mg', 'po', 'bid', '<eos>']\n",
      "['percocet', '<num>-<num>', 'tablets', 'po', 'q', '<num>', 'prn', '<eos>']\n",
      "['percocet', '<num>-<num>', 'tablets', 'po', 'q', '<num>', 'prn', '<eos>']\n",
      "['coumadin', '<eos>']\n",
      "['coumadin', '<num>', 'mg', 'in', 'evening', 'x', '<num>', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(res_words[i])\n",
    "    print(tru_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP\tFP\tFN\t\n",
      "1183\t246\t301\n",
      "Precision: 0.83\n",
      "Recall: 0.80\n",
      "Token-Level Horizontal Metric: 0.81\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "for i in range(360):\n",
    "    mistake = False\n",
    "    for word in res_words[i][:-1]:\n",
    "        if word in tru_words[i][:-1]:\n",
    "            tp +=1\n",
    "        else:\n",
    "            fp += 1\n",
    "            mistake = True\n",
    "    for word in tru_words[i][:-1]:\n",
    "        if word not in res_words[i][:-1]:\n",
    "            fn += 1\n",
    "            mistake = True\n",
    "    #if mistake:\n",
    "        #print(sets['test'][0][i])\n",
    "        #print(sets['test'])\n",
    "print('TP\\tFP\\tFN\\t')\n",
    "print('{}\\t{}\\t{}'.format(tp, fp, fn))\n",
    "print('Precision: {:.2f}'.format(tp / (tp + fp)))\n",
    "print('Recall: {:.2f}'.format(tp / (tp + fn)))\n",
    "print('Token-Level Horizontal Metric: {:.2f}'.format((2 * tp) / (2*tp + fn + fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s2s/model/model.ckpt'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(S2S.sess, \"s2s/model/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luka\\anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from s2s/model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "loaded = S2S_Model(decay = 0.00001,\n",
    "                batch=50,\n",
    "                enc_vocab_size=len(word_indices), \n",
    "                dec_vocab_size=len(word_indices), \n",
    "                enc_emb_size=100, \n",
    "                dec_emb_size=100, \n",
    "                state_size=128, \n",
    "                dropout=1.0,\n",
    "                learn_rate=0.001,\n",
    "                max_gradient_norm=5,\n",
    "                enc_emb_layer=emb_layer)\n",
    "loaded.build_graph()\n",
    "loaded.sess = tf.Session()\n",
    "loader = tf.train.Saver()\n",
    "loader.restore(loaded.sess, \"s2s/model/model.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
