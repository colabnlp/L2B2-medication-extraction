{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luka\\anaconda3\\envs\\tensorflow13\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import Functions as fn\n",
    "import Iterator as it\n",
    "from DS import DS\n",
    "from Set import pool\n",
    "from FFModel import FF_Model\n",
    "from RNNModel import RNN_Model\n",
    "From ELS2SModel import ELS2S_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Text Load Complete\n",
      "Raw Labels Load Complete\n"
     ]
    }
   ],
   "source": [
    "Dataset = pool()\n",
    "Dataset.load_texts('raw_texts')\n",
    "Dataset.load_labels('raw_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Load Complete\n"
     ]
    }
   ],
   "source": [
    "target_dict = fn.load_labels('final_meta/labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4585 238 10 10\n"
     ]
    }
   ],
   "source": [
    "train_set = pool(data=(Dataset.get_DS(stage='test', labelled='yes')).data[:-10])\n",
    "validation_set = pool(data=(Dataset.get_DS(stage='test', labelled='yes')).data[-10:])\n",
    "test_set = Dataset.get_DS(stage='train', labelled='yes')\n",
    "set_1 = Dataset.get_DS(stage='train', labelled='no')\n",
    "set_2 = Dataset.get_DS(stage='test', labelled='no')\n",
    "set_1.append(set_2.data)\n",
    "set_1.append(train_set.data)\n",
    "emb_set = set_1\n",
    "print(emb_set.size, train_set.size, validation_set.size, test_set.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Load Complete\n"
     ]
    }
   ],
   "source": [
    "#emb_set.process_for_embedding()\n",
    "#sentences = emb_set.get_sentences()\n",
    "#fn.write_sentences(sentences, 'final_meta/sentences')\n",
    "sentences = fn.load_sentences('final_meta/sentences')\n",
    "\n",
    "#model = Word2Vec(sentences, min_count=1, size=100)\n",
    "#model.save('final_meta/W2V')\n",
    "model = Word2Vec.load('final_meta/W2V')\n",
    "\n",
    "vocab = model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer and Index Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Indices Load Complete\n",
      "Embedding Layer Load Complete\n"
     ]
    }
   ],
   "source": [
    "#word_indices, emb_layer = fn.get_index_and_emb_layer(model)\n",
    "#fn.write_word_indices(word_indices, 's2s/word_indices')\n",
    "#fn.write_emb_layer(emb_layer, 's2s/emb_layer')\n",
    "\n",
    "word_indices = fn.load_word_indices('s2s/word_indices')\n",
    "emb_layer = fn.load_emb_layer('s2s/emb_layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELS2S Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set.process_for_els2s_testing()\n",
    "validation_set.process_for_els2s_testing()\n",
    "test_set.process_for_els2s_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 94\n"
     ]
    }
   ],
   "source": [
    "max_tok, max_inp = 0, 0\n",
    "for setin in [train_set, validation_set, test_set]:\n",
    "    for case in setin.data:\n",
    "        for inp_words in case.inp_words:\n",
    "            max_inp = max(max_inp, len(inp_words))\n",
    "        for inp_tok in case.inp_toks:\n",
    "            max_tok = max(max_tok, len(inp_tok))\n",
    "print(max_tok, max_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sets = {}\n",
    "sets['train'] = train_set.get_els2s_sets(word_indices, max_tok, max_inp)\n",
    "sets['validation'] = validation_set.get_els2s_sets(word_indices, max_tok, max_inp)\n",
    "sets['test'] = test_set.get_els2s_sets(word_indices, max_tok, max_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Learn Rate: 0.0010000, Perplexity: 1.94\n",
      "Epoch: 1, Learn Rate: 0.0010000, Perplexity: 0.93\n",
      "Epoch: 2, Learn Rate: 0.0010000, Perplexity: 0.81\n",
      "Epoch: 3, Learn Rate: 0.0010000, Perplexity: 0.67\n",
      "Epoch: 4, Learn Rate: 0.0010000, Perplexity: 0.57\n",
      "Epoch: 5, Learn Rate: 0.0010000, Perplexity: 0.54\n",
      "Epoch: 6, Learn Rate: 0.0010000, Perplexity: 0.43\n",
      "Epoch: 7, Learn Rate: 0.0010000, Perplexity: 0.36\n",
      "Epoch: 8, Learn Rate: 0.0010000, Perplexity: 0.29\n",
      "Epoch: 9, Learn Rate: 0.0010000, Perplexity: 0.27\n",
      "Epoch: 10, Learn Rate: 0.0010000, Perplexity: 0.22\n",
      "Epoch: 11, Learn Rate: 0.0010000, Perplexity: 0.18\n",
      "Epoch: 12, Learn Rate: 0.0010000, Perplexity: 0.17\n",
      "Epoch: 13, Learn Rate: 0.0010000, Perplexity: 0.15\n",
      "Epoch: 14, Learn Rate: 0.0010000, Perplexity: 0.12\n",
      "Epoch: 15, Learn Rate: 0.0010000, Perplexity: 0.12\n",
      "Epoch: 16, Learn Rate: 0.0010000, Perplexity: 0.10\n",
      "Epoch: 17, Learn Rate: 0.0010000, Perplexity: 0.08\n",
      "Epoch: 18, Learn Rate: 0.0010000, Perplexity: 0.07\n",
      "Epoch: 19, Learn Rate: 0.0010000, Perplexity: 0.07\n",
      "Epoch: 20, Learn Rate: 0.0010000, Perplexity: 0.06\n",
      "Epoch: 21, Learn Rate: 0.0010000, Perplexity: 0.06\n",
      "Epoch: 22, Learn Rate: 0.0010000, Perplexity: 0.05\n",
      "Epoch: 23, Learn Rate: 0.0010000, Perplexity: 0.04\n",
      "Epoch: 24, Learn Rate: 0.0010000, Perplexity: 0.04\n",
      "Epoch: 25, Learn Rate: 0.0010000, Perplexity: 0.03\n",
      "Epoch: 26, Learn Rate: 0.0010000, Perplexity: 0.03\n",
      "Epoch: 27, Learn Rate: 0.0010000, Perplexity: 0.03\n",
      "Epoch: 28, Learn Rate: 0.0010000, Perplexity: 0.02\n",
      "Epoch: 29, Learn Rate: 0.0010000, Perplexity: 0.04\n",
      "Epoch: 30, Learn Rate: 0.0010000, Perplexity: 0.03\n",
      "Epoch: 31, Learn Rate: 0.0010000, Perplexity: 0.02\n",
      "Epoch: 32, Learn Rate: 0.0010000, Perplexity: 0.02\n",
      "Epoch: 33, Learn Rate: 0.0010000, Perplexity: 0.02\n",
      "Epoch: 34, Learn Rate: 0.0010000, Perplexity: 0.02\n",
      "Epoch: 35, Learn Rate: 0.0010000, Perplexity: 0.01\n",
      "Epoch: 36, Learn Rate: 0.0010000, Perplexity: 0.01\n",
      "Epoch: 37, Learn Rate: 0.0010000, Perplexity: 0.01\n",
      "Epoch: 38, Learn Rate: 0.0010000, Perplexity: 0.01\n",
      "Epoch: 39, Learn Rate: 0.0010000, Perplexity: 0.01\n",
      "Epoch: 40, Learn Rate: 0.0010000, Perplexity: 0.01\n",
      "Epoch: 41, Learn Rate: 0.0010000, Perplexity: 0.02\n",
      "Epoch: 42, Learn Rate: 0.0010000, Perplexity: 0.01\n",
      "Epoch: 43, Learn Rate: 0.0010000, Perplexity: 0.01\n",
      "Epoch: 44, Learn Rate: 0.0010000, Perplexity: 0.01\n",
      "Epoch: 45, Learn Rate: 0.0010000, Perplexity: 0.01\n",
      "Epoch: 46, Learn Rate: 0.0010000, Perplexity: 0.01\n",
      "Epoch: 47, Learn Rate: 0.0010000, Perplexity: 0.01\n",
      "Epoch: 48, Learn Rate: 0.0010000, Perplexity: 0.01\n",
      "Epoch: 49, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 50, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 51, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 52, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 53, Learn Rate: 0.0010000, Perplexity: 0.01\n",
      "Epoch: 54, Learn Rate: 0.0010000, Perplexity: 0.01\n",
      "Epoch: 55, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 56, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 57, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 58, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 59, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 60, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 61, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 62, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 63, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 64, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 65, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 66, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 67, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 68, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 69, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 70, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 71, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 72, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 73, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 74, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 75, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 76, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 77, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 78, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 79, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 80, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 81, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 82, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 83, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 84, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 85, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 86, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 87, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 88, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 89, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 90, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 91, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 92, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 93, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 94, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 95, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 96, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 97, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 98, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 99, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Epoch: 100, Learn Rate: 0.0010000, Perplexity: 0.00\n",
      "Progress: 100%\r"
     ]
    }
   ],
   "source": [
    "ELS2S = ELS2S_Model(decay = 0.000025,\n",
    "                batch=50,\n",
    "                enc_vocab_size=len(word_indices), \n",
    "                dec_vocab_size=len(word_indices), \n",
    "                enc_emb_size=100, \n",
    "                dec_emb_size=100, \n",
    "                state_size=101, \n",
    "                dropout=1.0,\n",
    "                learn_rate=0.001,\n",
    "                max_gradient_norm=5,\n",
    "                enc_emb_layer=emb_layer)\n",
    "ELS2S.build_graph()\n",
    "ELS2S.train(sets=sets, epochs=100, report_percentage=1, show_progress=True, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tru_seqs = [label for entry in sets['test'][4] for label in entry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(len(sets['test'][0])):\n",
    "    dummy = [[], [], [], [], [], []]\n",
    "    for j in range(50):\n",
    "        for k in range(6):\n",
    "            dummy[k].append(sets['test'][k][i])\n",
    "    temp = ELS2S.predict(dummy)\n",
    "    res.append(temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_seqs = [label for entry in res for label in entry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82042494859492809"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk.metrics.f1_score(tru_seqs, res_seqs, labels=[1, 2, 3, 4, 5, 6], average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tru_seq_m = [1 if label==1 else 0 for label in tru_seqs]\n",
    "tru_seq_do = [1 if label==2 else 0 for label in tru_seqs]\n",
    "tru_seq_mo = [1 if label==3 else 0 for label in tru_seqs]\n",
    "tru_seq_f = [1 if label==4 else 0 for label in tru_seqs]\n",
    "tru_seq_du = [1 if label==5 else 0 for label in tru_seqs]\n",
    "tru_seq_r = [1 if label==6 else 0 for label in tru_seqs]\n",
    "\n",
    "res_seq_m = [1 if label==1 else 0 for label in res_seqs]\n",
    "res_seq_do = [1 if label==2 else 0 for label in res_seqs]\n",
    "res_seq_mo = [1 if label==3 else 0 for label in res_seqs]\n",
    "res_seq_f = [1 if label==4 else 0 for label in res_seqs]\n",
    "res_seq_du = [1 if label==5 else 0 for label in res_seqs]\n",
    "res_seq_r = [1 if label==6 else 0 for label in res_seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Med F1-Score: 0.892\n",
      "Dos F1-Score: 0.783\n",
      "Mod F1-Score: 0.840\n",
      "Fre F1-Score: 0.789\n",
      "Dur F1-Score: 0.764\n",
      "Rea F1-Score: 0.720\n"
     ]
    }
   ],
   "source": [
    "print('Med F1-Score: {:.3f}'.format(sk.metrics.f1_score(tru_seq_m, res_seq_m, average='binary')))\n",
    "print('Dos F1-Score: {:.3f}'.format(sk.metrics.f1_score(tru_seq_do, res_seq_do, average='binary')))\n",
    "print('Mod F1-Score: {:.3f}'.format(sk.metrics.f1_score(tru_seq_mo, res_seq_mo, average='binary')))\n",
    "print('Fre F1-Score: {:.3f}'.format(sk.metrics.f1_score(tru_seq_f, res_seq_f, average='binary')))\n",
    "print('Dur F1-Score: {:.3f}'.format(sk.metrics.f1_score(tru_seq_du, res_seq_du, average='binary')))\n",
    "print('Rea F1-Score: {:.3f}'.format(sk.metrics.f1_score(tru_seq_r, res_seq_r, average='binary')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s2s/model/model.ckpt'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(S2S.sess, \"s2s/model/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luka\\anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from s2s/model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "loaded = S2S_Model(decay = 0.00001,\n",
    "                batch=50,\n",
    "                enc_vocab_size=len(word_indices), \n",
    "                dec_vocab_size=len(word_indices), \n",
    "                enc_emb_size=100, \n",
    "                dec_emb_size=100, \n",
    "                state_size=128, \n",
    "                dropout=1.0,\n",
    "                learn_rate=0.001,\n",
    "                max_gradient_norm=5,\n",
    "                enc_emb_layer=emb_layer)\n",
    "loaded.build_graph()\n",
    "loaded.sess = tf.Session()\n",
    "loader = tf.train.Saver()\n",
    "loader.restore(loaded.sess, \"s2s/model/model.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
