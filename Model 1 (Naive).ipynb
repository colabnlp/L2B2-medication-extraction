{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luka\\anaconda3\\envs\\tensorflow13\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import Functions as fn\n",
    "from DS import DS\n",
    "from Set import pool\n",
    "from Iterator import Iterator\n",
    "from FFModel import FF_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Text Load Complete\n",
      "Raw Labels Load Complete\n"
     ]
    }
   ],
   "source": [
    "Dataset = pool()\n",
    "Dataset.load_texts('raw_texts')\n",
    "Dataset.load_labels('raw_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print('Number of Texts: ', Dataset.size)\n",
    "#print('Number of 2007 Smoking Challenge texts: ', Dataset.number_of(challenge='2007 Smoking Challenge'))\n",
    "#print('Number of 2008 ObesityChallenge texts: ', Dataset.number_of(challenge='2008 Obesity Challenge'))\n",
    "#print('Number of 2009 Medication Challenge texts: ', Dataset.number_of(challenge='2009 Medication Challenge'))\n",
    "#print('Number of 2010 Relations Challenge texts: ', Dataset.number_of(challenge='2010 Relations Challenge'))\n",
    "#print('Number of 2011 Coreference Challenge texts: ', Dataset.number_of(challenge='2011 Coreference Challenge'))\n",
    "#print('Number of 2012 Temporal Relations Challenge texts: ', Dataset.number_of(challenge='2012 Temporal Relations Challenge'))\n",
    "#print('Number of Train Texts: ', Dataset.number_of(stage='train'))\n",
    "#print('Number of Test Texts: ', Dataset.number_of(stage='test'))\n",
    "#print('Number of Labeled Texts: ', Dataset.number_of(labelled='yes'))\n",
    "#print('Number of Initially Labeled Texts: ', Dataset.number_of(labelled='yes', label_type='train'))\n",
    "#print('Number of Competitor Labeled Texts Texts: ', Dataset.number_of(labelled='yes', label_type='test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Load Complete\n"
     ]
    }
   ],
   "source": [
    "target_dict = fn.load_labels('final_meta/labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4585 238 10 10\n"
     ]
    }
   ],
   "source": [
    "train_set = pool(data=(Dataset.get_DS(stage='test', labelled='yes')).data[:-10])\n",
    "validation_set = pool(data=(Dataset.get_DS(stage='test', labelled='yes')).data[-10:])\n",
    "test_set = Dataset.get_DS(stage='train', labelled='yes')\n",
    "set_1 = Dataset.get_DS(stage='train', labelled='no')\n",
    "set_2 = Dataset.get_DS(stage='test', labelled='no')\n",
    "set_1.append(set_2.data)\n",
    "set_1.append(train_set.data)\n",
    "emb_set = set_1\n",
    "print(emb_set.size, train_set.size, validation_set.size, test_set.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Load Complete\n"
     ]
    }
   ],
   "source": [
    "#emb_set.process_for_embedding()\n",
    "#sentences = emb_set.get_sentences()\n",
    "#fn.write_sentences(sentences, 'final_meta/sentences')\n",
    "sentences = fn.load_sentences('final_meta/sentences')\n",
    "\n",
    "#model = Word2Vec(sentences, min_count=1, size=100)\n",
    "#model.save('final_meta/W2V')\n",
    "model = Word2Vec.load('final_meta/W2V')\n",
    "\n",
    "vocab = model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AED and ACS Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "durat AED and CSS: 16.77 \t 0.08\n",
      "frequ AED and CSS: 14.42 \t 0.17\n",
      "modes AED and CSS: 10.05 \t 0.23\n",
      "reaso AED and CSS: 12.55 \t 0.10\n",
      "dosag AED and CSS: 11.78 \t 0.16\n",
      "medic AED and CSS: 6.49 \t 0.24\n"
     ]
    }
   ],
   "source": [
    "for target in target_dict.keys():\n",
    "    dist = 0\n",
    "    sim = 0\n",
    "    cn = len(target_dict[target]) * len(target_dict[target])\n",
    "    for word in target_dict[target]:\n",
    "        for word2 in target_dict[target]:\n",
    "            if word in vocab and word2 in vocab:\n",
    "                dist += np.linalg.norm(model[word]-model[word2])\n",
    "                sim += model.similarity(word, word2)\n",
    "    print('{} AED and CSS: {:.2f} \\t {:.2f}'.format(target[:5], dist/cn, sim/cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modes AED and CSS: 2.96 \t 0.62\n",
      "frequ AED and CSS: 2.95 \t 0.61\n",
      "durat AED and CSS: 2.95 \t 0.55\n",
      "dosag AED and CSS: 2.84 \t 0.61\n",
      "reaso AED and CSS: 3.08 \t 0.53\n",
      "medic AED and CSS: 2.61 \t 0.67\n"
     ]
    }
   ],
   "source": [
    "for target in target_dict.keys():\n",
    "    dist = 0\n",
    "    sim = 0\n",
    "    cn = len(target_dict[target]) * len(target_dict[target])\n",
    "    for word in target_dict[target]:\n",
    "        for word2 in target_dict[target]:\n",
    "            if word in vocab and word2 in vocab:\n",
    "                dist += np.linalg.norm(model[word]-model[word2])\n",
    "                sim += model.similarity(word, word2)\n",
    "    print('{} AED and CSS: {:.2f} \\t {:.2f}'.format(target[:5], dist/cn, sim/cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random words AED and CSS: 17.15 \t 0.04\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "dist = 0\n",
    "sim = 0\n",
    "sample = Counter([word for sent in sentences for word in sent]).most_common(2000)\n",
    "sample = np.ndarray.tolist(np.array(sample)[:,0])\n",
    "cn = len(sample) * len(sample)\n",
    "for word in sample:\n",
    "    for word2 in sample:\n",
    "        dist += np.linalg.norm(model[word]-model[word2])\n",
    "        sim += model.similarity(word, word2)\n",
    "print('random words AED and CSS: {:.2f} \\t {:.2f}'.format(dist/cn, sim/cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "dist = 0\n",
    "sim = 0\n",
    "sample = Counter([word for sent in sentences for word in sent]).most_common(2000)\n",
    "sample = np.ndarray.tolist(np.array(sample)[:,0])\n",
    "cn = len(sample) * len(sample)\n",
    "for word in sample:\n",
    "    for word2 in sample:\n",
    "        dist += np.linalg.norm(model[word]-model[word2])\n",
    "        sim += model.similarity(word, word2)\n",
    "print('random words AED and CSS: {:.2f} \\t {:.2f}'.format(dist/cn, sim/cn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Scale AED and ACS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 16 0 medications\n",
      "0 16 0 dosages\n",
      "0 16 0 modes\n",
      "0 16 0 frequencies\n",
      "0 16 0 durations\n",
      "0 16 0 reasons\n",
      "0 16 1 medications\n",
      "0 16 1 dosages\n",
      "0 16 1 modes\n",
      "0 16 1 frequencies\n",
      "0 16 1 durations\n",
      "0 16 1 reasons\n",
      "0 16 2 medications\n",
      "0 16 2 dosages\n",
      "0 16 2 modes\n",
      "0 16 2 frequencies\n",
      "0 16 2 durations\n",
      "0 16 2 reasons\n",
      "0 16 3 medications\n",
      "0 16 3 dosages\n",
      "0 16 3 modes\n",
      "0 16 3 frequencies\n",
      "0 16 3 durations\n",
      "0 16 3 reasons\n",
      "0 16 4 medications\n",
      "0 16 4 dosages\n",
      "0 16 4 modes\n",
      "0 16 4 frequencies\n",
      "0 16 4 durations\n",
      "0 16 4 reasons\n",
      "0 32 0 medications\n",
      "0 32 0 dosages\n",
      "0 32 0 modes\n",
      "0 32 0 frequencies\n",
      "0 32 0 durations\n",
      "0 32 0 reasons\n",
      "0 32 1 medications\n",
      "0 32 1 dosages\n",
      "0 32 1 modes\n",
      "0 32 1 frequencies\n",
      "0 32 1 durations\n",
      "0 32 1 reasons\n",
      "0 32 2 medications\n",
      "0 32 2 dosages\n",
      "0 32 2 modes\n",
      "0 32 2 frequencies\n",
      "0 32 2 durations\n",
      "0 32 2 reasons\n",
      "0 32 3 medications\n",
      "0 32 3 dosages\n",
      "0 32 3 modes\n",
      "0 32 3 frequencies\n",
      "0 32 3 durations\n",
      "0 32 3 reasons\n",
      "0 32 4 medications\n",
      "0 32 4 dosages\n",
      "0 32 4 modes\n",
      "0 32 4 frequencies\n",
      "0 32 4 durations\n",
      "0 32 4 reasons\n",
      "0 64 0 medications\n",
      "0 64 0 dosages\n",
      "0 64 0 modes\n",
      "0 64 0 frequencies\n",
      "0 64 0 durations\n",
      "0 64 0 reasons\n",
      "0 64 1 medications\n",
      "0 64 1 dosages\n",
      "0 64 1 modes\n",
      "0 64 1 frequencies\n",
      "0 64 1 durations\n",
      "0 64 1 reasons\n",
      "0 64 2 medications\n",
      "0 64 2 dosages\n",
      "0 64 2 modes\n",
      "0 64 2 frequencies\n",
      "0 64 2 durations\n",
      "0 64 2 reasons\n",
      "0 64 3 medications\n",
      "0 64 3 dosages\n",
      "0 64 3 modes\n",
      "0 64 3 frequencies\n",
      "0 64 3 durations\n",
      "0 64 3 reasons\n",
      "0 64 4 medications\n",
      "0 64 4 dosages\n",
      "0 64 4 modes\n",
      "0 64 4 frequencies\n",
      "0 64 4 durations\n",
      "0 64 4 reasons\n",
      "0 128 0 medications\n",
      "0 128 0 dosages\n",
      "0 128 0 modes\n",
      "0 128 0 frequencies\n",
      "0 128 0 durations\n",
      "0 128 0 reasons\n",
      "0 128 1 medications\n",
      "0 128 1 dosages\n",
      "0 128 1 modes\n",
      "0 128 1 frequencies\n",
      "0 128 1 durations\n",
      "0 128 1 reasons\n",
      "0 128 2 medications\n",
      "0 128 2 dosages\n",
      "0 128 2 modes\n",
      "0 128 2 frequencies\n",
      "0 128 2 durations\n",
      "0 128 2 reasons\n",
      "0 128 3 medications\n",
      "0 128 3 dosages\n",
      "0 128 3 modes\n",
      "0 128 3 frequencies\n",
      "0 128 3 durations\n",
      "0 128 3 reasons\n",
      "0 128 4 medications\n",
      "0 128 4 dosages\n",
      "0 128 4 modes\n",
      "0 128 4 frequencies\n",
      "0 128 4 durations\n",
      "0 128 4 reasons\n",
      "0 256 0 medications\n",
      "0 256 0 dosages\n",
      "0 256 0 modes\n",
      "0 256 0 frequencies\n",
      "0 256 0 durations\n",
      "0 256 0 reasons\n",
      "0 256 1 medications\n",
      "0 256 1 dosages\n",
      "0 256 1 modes\n",
      "0 256 1 frequencies\n",
      "0 256 1 durations\n",
      "0 256 1 reasons\n",
      "0 256 2 medications\n",
      "0 256 2 dosages\n",
      "0 256 2 modes\n",
      "0 256 2 frequencies\n",
      "0 256 2 durations\n",
      "0 256 2 reasons\n",
      "0 256 3 medications\n",
      "0 256 3 dosages\n",
      "0 256 3 modes\n",
      "0 256 3 frequencies\n",
      "0 256 3 durations\n",
      "0 256 3 reasons\n",
      "0 256 4 medications\n",
      "0 256 4 dosages\n",
      "0 256 4 modes\n",
      "0 256 4 frequencies\n",
      "0 256 4 durations\n",
      "0 256 4 reasons\n",
      "0 512 0 medications\n",
      "0 512 0 dosages\n",
      "0 512 0 modes\n",
      "0 512 0 frequencies\n",
      "0 512 0 durations\n",
      "0 512 0 reasons\n",
      "0 512 1 medications\n",
      "0 512 1 dosages\n",
      "0 512 1 modes\n",
      "0 512 1 frequencies\n",
      "0 512 1 durations\n",
      "0 512 1 reasons\n",
      "0 512 2 medications\n",
      "0 512 2 dosages\n",
      "0 512 2 modes\n",
      "0 512 2 frequencies\n",
      "0 512 2 durations\n",
      "0 512 2 reasons\n",
      "0 512 3 medications\n",
      "0 512 3 dosages\n",
      "0 512 3 modes\n",
      "0 512 3 frequencies\n",
      "0 512 3 durations\n",
      "0 512 3 reasons\n",
      "0 512 4 medications\n",
      "0 512 4 dosages\n",
      "0 512 4 modes\n",
      "0 512 4 frequencies\n",
      "0 512 4 durations\n",
      "0 512 4 reasons\n",
      "0 1024 0 medications\n",
      "0 1024 0 dosages\n",
      "0 1024 0 modes\n",
      "0 1024 0 frequencies\n",
      "0 1024 0 durations\n",
      "0 1024 0 reasons\n",
      "0 1024 1 medications\n",
      "0 1024 1 dosages\n",
      "0 1024 1 modes\n",
      "0 1024 1 frequencies\n",
      "0 1024 1 durations\n",
      "0 1024 1 reasons\n",
      "0 1024 2 medications\n",
      "0 1024 2 dosages\n",
      "0 1024 2 modes\n",
      "0 1024 2 frequencies\n",
      "0 1024 2 durations\n",
      "0 1024 2 reasons\n",
      "0 1024 3 medications\n",
      "0 1024 3 dosages\n",
      "0 1024 3 modes\n",
      "0 1024 3 frequencies\n",
      "0 1024 3 durations\n",
      "0 1024 3 reasons\n",
      "0 1024 4 medications\n",
      "0 1024 4 dosages\n",
      "0 1024 4 modes\n",
      "0 1024 4 frequencies\n",
      "0 1024 4 durations\n",
      "0 1024 4 reasons\n",
      "1 16 0 medications\n",
      "1 16 0 dosages\n",
      "1 16 0 modes\n",
      "1 16 0 frequencies\n",
      "1 16 0 durations\n",
      "1 16 0 reasons\n",
      "1 16 1 medications\n",
      "1 16 1 dosages\n",
      "1 16 1 modes\n",
      "1 16 1 frequencies\n",
      "1 16 1 durations\n",
      "1 16 1 reasons\n",
      "1 16 2 medications\n",
      "1 16 2 dosages\n",
      "1 16 2 modes\n",
      "1 16 2 frequencies\n",
      "1 16 2 durations\n",
      "1 16 2 reasons\n",
      "1 16 3 medications\n",
      "1 16 3 dosages\n",
      "1 16 3 modes\n",
      "1 16 3 frequencies\n",
      "1 16 3 durations\n",
      "1 16 3 reasons\n",
      "1 16 4 medications\n",
      "1 16 4 dosages\n",
      "1 16 4 modes\n",
      "1 16 4 frequencies\n",
      "1 16 4 durations\n",
      "1 16 4 reasons\n",
      "1 32 0 medications\n",
      "1 32 0 dosages\n",
      "1 32 0 modes\n",
      "1 32 0 frequencies\n",
      "1 32 0 durations\n",
      "1 32 0 reasons\n",
      "1 32 1 medications\n",
      "1 32 1 dosages\n",
      "1 32 1 modes\n",
      "1 32 1 frequencies\n",
      "1 32 1 durations\n",
      "1 32 1 reasons\n",
      "1 32 2 medications\n",
      "1 32 2 dosages\n",
      "1 32 2 modes\n",
      "1 32 2 frequencies\n",
      "1 32 2 durations\n",
      "1 32 2 reasons\n",
      "1 32 3 medications\n",
      "1 32 3 dosages\n",
      "1 32 3 modes\n",
      "1 32 3 frequencies\n",
      "1 32 3 durations\n",
      "1 32 3 reasons\n",
      "1 32 4 medications\n",
      "1 32 4 dosages\n",
      "1 32 4 modes\n",
      "1 32 4 frequencies\n",
      "1 32 4 durations\n",
      "1 32 4 reasons\n",
      "1 64 0 medications\n",
      "1 64 0 dosages\n",
      "1 64 0 modes\n",
      "1 64 0 frequencies\n",
      "1 64 0 durations\n",
      "1 64 0 reasons\n",
      "1 64 1 medications\n",
      "1 64 1 dosages\n",
      "1 64 1 modes\n",
      "1 64 1 frequencies\n",
      "1 64 1 durations\n",
      "1 64 1 reasons\n",
      "1 64 2 medications\n",
      "1 64 2 dosages\n",
      "1 64 2 modes\n",
      "1 64 2 frequencies\n",
      "1 64 2 durations\n",
      "1 64 2 reasons\n",
      "1 64 3 medications\n",
      "1 64 3 dosages\n",
      "1 64 3 modes\n",
      "1 64 3 frequencies\n",
      "1 64 3 durations\n",
      "1 64 3 reasons\n",
      "1 64 4 medications\n",
      "1 64 4 dosages\n",
      "1 64 4 modes\n",
      "1 64 4 frequencies\n",
      "1 64 4 durations\n",
      "1 64 4 reasons\n",
      "1 128 0 medications\n",
      "1 128 0 dosages\n",
      "1 128 0 modes\n",
      "1 128 0 frequencies\n",
      "1 128 0 durations\n",
      "1 128 0 reasons\n",
      "1 128 1 medications\n",
      "1 128 1 dosages\n",
      "1 128 1 modes\n",
      "1 128 1 frequencies\n",
      "1 128 1 durations\n",
      "1 128 1 reasons\n",
      "1 128 2 medications\n",
      "1 128 2 dosages\n",
      "1 128 2 modes\n",
      "1 128 2 frequencies\n",
      "1 128 2 durations\n",
      "1 128 2 reasons\n",
      "1 128 3 medications\n",
      "1 128 3 dosages\n",
      "1 128 3 modes\n",
      "1 128 3 frequencies\n",
      "1 128 3 durations\n",
      "1 128 3 reasons\n",
      "1 128 4 medications\n",
      "1 128 4 dosages\n",
      "1 128 4 modes\n",
      "1 128 4 frequencies\n",
      "1 128 4 durations\n",
      "1 128 4 reasons\n",
      "1 256 0 medications\n",
      "1 256 0 dosages\n",
      "1 256 0 modes\n",
      "1 256 0 frequencies\n",
      "1 256 0 durations\n",
      "1 256 0 reasons\n",
      "1 256 1 medications\n",
      "1 256 1 dosages\n",
      "1 256 1 modes\n",
      "1 256 1 frequencies\n",
      "1 256 1 durations\n",
      "1 256 1 reasons\n",
      "1 256 2 medications\n",
      "1 256 2 dosages\n",
      "1 256 2 modes\n",
      "1 256 2 frequencies\n",
      "1 256 2 durations\n",
      "1 256 2 reasons\n",
      "1 256 3 medications\n",
      "1 256 3 dosages\n",
      "1 256 3 modes\n",
      "1 256 3 frequencies\n",
      "1 256 3 durations\n",
      "1 256 3 reasons\n",
      "1 256 4 medications\n",
      "1 256 4 dosages\n",
      "1 256 4 modes\n",
      "1 256 4 frequencies\n",
      "1 256 4 durations\n",
      "1 256 4 reasons\n",
      "1 512 0 medications\n",
      "1 512 0 dosages\n",
      "1 512 0 modes\n",
      "1 512 0 frequencies\n",
      "1 512 0 durations\n",
      "1 512 0 reasons\n",
      "1 512 1 medications\n",
      "1 512 1 dosages\n",
      "1 512 1 modes\n",
      "1 512 1 frequencies\n",
      "1 512 1 durations\n",
      "1 512 1 reasons\n",
      "1 512 2 medications\n",
      "1 512 2 dosages\n",
      "1 512 2 modes\n",
      "1 512 2 frequencies\n",
      "1 512 2 durations\n",
      "1 512 2 reasons\n",
      "1 512 3 medications\n",
      "1 512 3 dosages\n",
      "1 512 3 modes\n",
      "1 512 3 frequencies\n",
      "1 512 3 durations\n",
      "1 512 3 reasons\n",
      "1 512 4 medications\n",
      "1 512 4 dosages\n",
      "1 512 4 modes\n",
      "1 512 4 frequencies\n",
      "1 512 4 durations\n",
      "1 512 4 reasons\n",
      "1 1024 0 medications\n",
      "1 1024 0 dosages\n",
      "1 1024 0 modes\n",
      "1 1024 0 frequencies\n",
      "1 1024 0 durations\n",
      "1 1024 0 reasons\n",
      "1 1024 1 medications\n",
      "1 1024 1 dosages\n",
      "1 1024 1 modes\n",
      "1 1024 1 frequencies\n",
      "1 1024 1 durations\n",
      "1 1024 1 reasons\n",
      "1 1024 2 medications\n",
      "1 1024 2 dosages\n",
      "1 1024 2 modes\n",
      "1 1024 2 frequencies\n",
      "1 1024 2 durations\n",
      "1 1024 2 reasons\n",
      "1 1024 3 medications\n",
      "1 1024 3 dosages\n",
      "1 1024 3 modes\n",
      "1 1024 3 frequencies\n",
      "1 1024 3 durations\n",
      "1 1024 3 reasons\n",
      "1 1024 4 medications\n",
      "1 1024 4 dosages\n",
      "1 1024 4 modes\n",
      "1 1024 4 frequencies\n",
      "1 1024 4 durations\n",
      "1 1024 4 reasons\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "targets = ['medications', 'dosages', 'modes', 'frequencies', 'durations', 'reasons']\n",
    "methods = {'CBOW': 0, 'CSG': 1}\n",
    "averages = np.array([[[[0, 0] for i in range(7)] for j in range(7)] for k in range(2)])\n",
    "sizes = [16, 32, 64, 128, 256, 512, 1024]\n",
    "sample = Counter([word for sent in sentences for word in sent]).most_common(2000)\n",
    "sample = np.ndarray.tolist(np.array(sample)[:,0])\n",
    "sn = len(sample) * len(sample)\n",
    "\n",
    "for method in [0, 1]:\n",
    "    for i in range(len(sizes)):\n",
    "        for j in range(5):\n",
    "            model = Word2Vec(sentences, min_count=1, sg=method, size=sizes[i])\n",
    "            for k in range(len(targets)):\n",
    "                print(method, sizes[i], j, targets[k])\n",
    "                dist = 0\n",
    "                sim = 0\n",
    "                cn = len(target_dict[targets[k]]) * len(target_dict[targets[k]])\n",
    "                for word in target_dict[targets[k]]:\n",
    "                    for word2 in target_dict[targets[k]]:\n",
    "                        if word in vocab and word2 in vocab:\n",
    "                            dist += np.linalg.norm(model[word]-model[word2])\n",
    "                            sim += model.similarity(word, word2)\n",
    "                averages[method, i, k, 0] += dist / cn\n",
    "                averages[method, i, k, 1] += sim / cn\n",
    "            dist = 0\n",
    "            sim = 0\n",
    "            for word in sample:\n",
    "                for word2 in sample:\n",
    "                    dist += np.linalg.norm(model[word]-model[word2])\n",
    "                    sim += model.similarity(word, word2)\n",
    "            averages[method, i, 6, 0] += dist / sn\n",
    "            averages[method, i, 6, 1] += sim / sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n",
      "Met:\tSize:\tTarget:\tAED:\tACS:\n",
      "CBOW\t16\tmedi\t5.2589\t0.3518\n",
      "CBOW\t16\tdosa\t9.2174\t0.2465\n",
      "CBOW\t16\tmode\t8.4866\t0.3058\n",
      "CBOW\t16\tfreq\t11.1799\t0.2573\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "methods = {'CBOW': 0, 'CSG': 1}\n",
    "sizes = [16, 32, 64, 128, 256, 512, 1024]\n",
    "targets = ['medications', 'dosages', 'modes', 'frequencies', 'durations', 'reasons']\n",
    "mod_num = 3\n",
    "total_mod_num = len(methods) * len(sizes) * (1+len(targets)) * mod_num\n",
    "print(total_mod_num)\n",
    "\n",
    "#methods = {'CBOW': 0, 'CSG': 1}\n",
    "#sizes = [16]\n",
    "#targets = ['medications', 'dosages', 'modes', 'frequencies', 'durations', 'reasons']\n",
    "#mod_num = 1\n",
    "#total_mod_num = len(methods) * len(sizes) * mod_num\n",
    "#print(total_mod_num)\n",
    "\n",
    "averages = np.array([[[[0, 0] for i in range(7)] for j in range(len(sizes))] for k in range(len(methods))], dtype=np.float32)\n",
    "\n",
    "sample = Counter([word for sent in sentences for word in sent]).most_common(2000)\n",
    "sample = np.ndarray.tolist(np.array(sample)[:,0])\n",
    "sn = len(sample) * (len(sample) - 1) / 2\n",
    "\n",
    "n = 0\n",
    "timestamp = re.sub(r':', '-', str(datetime.datetime.now()).split('.')[0])\n",
    "\n",
    "with open('tests/embs/' + timestamp, 'w+') as f:\n",
    "    print('Met:\\tSize:\\tTarget:\\tAED:\\tACS:')\n",
    "    f.write('Met:\\tSize:\\tTarget:\\tAED:\\tACS:\\n')\n",
    "    for method in methods.keys():\n",
    "        for i in range(len(sizes)):\n",
    "            for j in range(mod_num):\n",
    "                n += 1\n",
    "                print('Model: {}/{}'.format(n, total_mod_num), end='\\r')\n",
    "                model = Word2Vec(sentences, min_count=1, sg=methods[method], size=sizes[i])\n",
    "                for k in range(len(targets)):\n",
    "                    dist = 0\n",
    "                    sim = 0\n",
    "                    cn = len(target_dict[targets[k]]) * (len(target_dict[targets[k]]) - 1) / 2\n",
    "                    vocab1 = target_dict[targets[k]].copy()\n",
    "                    vocab2 = target_dict[targets[k]].copy()\n",
    "                    for word1 in vocab1:\n",
    "                        vocab2.remove(word1)\n",
    "                        for word2 in vocab2:\n",
    "                            if word1 in vocab and word2 in vocab:\n",
    "                                dist += np.linalg.norm(model[word1]-model[word2])\n",
    "                                sim += model.similarity(word1, word2)\n",
    "                                #print(word1, word2, dist, sim)\n",
    "                    #print(dist)\n",
    "                    #print(sim)\n",
    "                    #print(cn)\n",
    "                    #print(dist/cn, sim/cn)\n",
    "                    averages[methods[method], i, k, 0] += dist / cn\n",
    "                    averages[methods[method], i, k, 1] += sim / cn\n",
    "                    #print('{}\\t{}\\t{}\\t{:.4f}\\t{:.4f}'.format(method, sizes[i], targets[k][:4], averages[methods[method], i, k, 0], averages[methods[method], i, k, 1]))\n",
    "                dist = 0\n",
    "                sim = 0\n",
    "                vocab1 = sample.copy()\n",
    "                vocab2 = sample.copy()\n",
    "                for word1 in vocab1:\n",
    "                    vocab2.remove(word1)\n",
    "                    for word2 in vocab2:\n",
    "                        dist += np.linalg.norm(model[word1]-model[word2])\n",
    "                        sim += model.similarity(word1, word2)\n",
    "                averages[methods[method], i, 6, 0] += dist / sn\n",
    "                averages[methods[method], i, 6, 1] += sim / sn\n",
    "            averages[methods[method], i] = averages[methods[method], i] / mod_num\n",
    "            for l in range(len(targets)):\n",
    "                print('{}\\t{}\\t{}\\t{:.4f}\\t{:.4f}'.format(method, sizes[i], targets[l][:4], averages[methods[method], i, l, 0], averages[methods[method], i, l, 1]))\n",
    "                f.write('{}\\t{}\\t{}\\t{:.4f}\\t{:.4f}\\n'.format(method, sizes[i], targets[l][:4], averages[methods[method], i, l, 0], averages[methods[method], i, l, 1]))\n",
    "            print('{}\\t{}\\t{}\\t{:.4f}\\t{:.4f}\\n'.format(method, sizes[i], 'rand', averages[methods[method], i, 6, 0], averages[methods[method], i, 6, 1]))\n",
    "            f.write('{}\\t{}\\t{}\\t{:.4f}\\t{:.4f}\\n\\n'.format(method, sizes[i], 'rand', averages[methods[method], i, 6, 0], averages[methods[method], i, 6, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn.visualise(model, sentences, [target_dict['reasons']], 1000, 'Medications in top 1000 words')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.most_similar(\"aspirin\", topn=10)\n",
    "model.most_similar_cosmul('aspirin')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "print_set = []\n",
    "for case in Dataset.get_DS(labelled='yes').data:\n",
    "    for term in re.finditer(r'do=\"[^|]+\\|', case.raw_labels):\n",
    "        print_set.append(term.group()[:-1])\n",
    "print(*print_set, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: medications\tRepetitions: True\n",
      "FInal Values: Tr-F1: 0.8531, Val-F1: 0.8333\n",
      "Test F1-Score: 0.8333\n",
      "\n",
      "Target: medications\tRepetitions: False\n",
      "FInal Values: Tr-F1: 0.8305, Val-F1: 0.7714\n",
      "Test F1-Score: 0.7677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for target in ['medications']:\n",
    "    for reps in [True, False]:\n",
    "        target_size = len(target_dict[target])\n",
    "        word_sets = fn.generate_naive_traintest(vocab, target_dict[target], target_size * 5, target_size, 10, 50, reps, reps)\n",
    "        emb_sets = fn.embed_words(word_sets, model)\n",
    "        emb_sets['validation_set'] = emb_sets['test_set']\n",
    "        emb_sets['validation_labels'] = emb_sets['test_labels']\n",
    "        print(\"Target: {}\\tRepetitions: {}\".format(target, reps))\n",
    "        NN = FF_Model()\n",
    "        NN.build_graph()\n",
    "        NN.train(emb_sets, epochs=50, report_percentage=10, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377300\n"
     ]
    }
   ],
   "source": [
    "emb_model = {'CBOW': 0, 'CSG': 1}\n",
    "NN_num = 10\n",
    "emb_sizes = [16, 32, 64, 128, 256, 512, 1024]\n",
    "layers = [[16], [32], [64], [128], [256], [512], [1024]]\n",
    "dropouts = [0.1, 0.2, 0.3, 0.4, 0.5, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "learn_rates = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "epoch_nums = [2, 4, 8, 16, 32, 64, 128]\n",
    "\n",
    "model_num = len(emb_model) * NN_num * len(emb_sizes) * len(layers) * len(dropouts) * \\\n",
    "            len(learn_rates) * len(epoch_nums)\n",
    "target = target_dict['medications']\n",
    "\n",
    "print(model_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_sets = fn.generate_naive_traintest(vocab=vocab,\n",
    "                                        labels=target,\n",
    "                                        train_size=10000,\n",
    "                                        test_size=1000,\n",
    "                                        train_label_percentage=10,\n",
    "                                        test_label_percentage=10,\n",
    "                                        word_repetition = True,\n",
    "                                        label_repetition = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterations = [emb_sizes, layers, dropouts, learn_rates, epoch_nums, batch_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "parameters = []\n",
    "results = []\n",
    "timestamp = re.sub(r':', '-', str(datetime.datetime.now()).split('.')[0])\n",
    "\n",
    "with open('tests/Model1/' + timestamp, 'w+') as f:\n",
    "    print('EmbSz:\\tLay:\\tDrop:\\tLeRa:\\tEpochs:\\tBatSz:\\tF1:')\n",
    "    f.write('EmbSz:\\tLay:\\tDrop:\\tLeRa:\\tEpochs:\\tBatSz:\\tF1:\\n')\n",
    "    for par in itertools.product(*iterations):\n",
    "        best = 0\n",
    "        parameters.append(par)\n",
    "        for i in range(emb_num):\n",
    "            model = Word2Vec(sentences, min_count=1, size=par[0])\n",
    "            emb_sets = fn.embed_words(word_sets, model)\n",
    "            emb_sets['validation_set'] = emb_sets['test_set']\n",
    "            emb_sets['validation_labels'] = emb_sets['test_labels']\n",
    "            for j in range(NN_num):\n",
    "                n += 1\n",
    "                print('Model Number: {}/{}'.format(n, model_num), end='\\r')\n",
    "                NN = FF_Model(input_size=par[0], layers=par[1], dropout=par[2], learn_rate=par[3])\n",
    "                NN.build_graph()\n",
    "                _, _, _, score = NN.train(emb_sets, epochs=par[4], batch=par[5], report_percentage=report_percentage)\n",
    "                best = max(best, score)\n",
    "        results.append(best)\n",
    "        print('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{:.4f}'.format(*parameters[-1], results[-1]))\n",
    "        f.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{:.4f}\\n'.format(*parameters[-1], results[-1]))\n",
    "\n",
    "    print('Max Performance: {:.4f}'.format(max(results)))  \n",
    "    f.write('Max Performance: {:.4f}\\n'.format(max(results)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
